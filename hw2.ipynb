{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKpYnj9Et/Pi51tYdPCs0H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eridanletalis/GB_nn/blob/main/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk1zBf_u6TS2"
      },
      "source": [
        "Начнём решать задачу с загрузки библиотек и датасета FASHION-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NGAnRvb5qEQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5xEjwl76X8q"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mL7RlCK8Dpf"
      },
      "source": [
        "Словарь-подсказка для меток\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfpOW-cB6eSx"
      },
      "source": [
        "fashion_dict = {\n",
        "    0:\"T-shirt/top\",\n",
        "    1:\"Trouser\",\n",
        "    2:\"Pullover\",\n",
        "    3:\"Dress\",\n",
        "    4:\"Coat\",\n",
        "    5:\"Sandal\",\n",
        "    6:\"Shirt\",\n",
        "    7:\"Sneaker\",\n",
        "    8:\"Bag\",\n",
        "    9:\"Ankle boot\"\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v1eme6c8rdM"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKl68nOv8w1x",
        "outputId": "9714dbfa-3694-4ac6-9ee7-6b63b085e188"
      },
      "source": [
        "pd.DataFrame(y_train).value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9    6000\n",
              "8    6000\n",
              "7    6000\n",
              "6    6000\n",
              "5    6000\n",
              "4    6000\n",
              "3    6000\n",
              "2    6000\n",
              "1    6000\n",
              "0    6000\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok7zVXfD9MNc",
        "outputId": "1dac3225-7e6d-4f95-a7cf-0a15ff944d39"
      },
      "source": [
        "pd.DataFrame(y_test).value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9    1000\n",
              "8    1000\n",
              "7    1000\n",
              "6    1000\n",
              "5    1000\n",
              "4    1000\n",
              "3    1000\n",
              "2    1000\n",
              "1    1000\n",
              "0    1000\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSUVxWni9iGP"
      },
      "source": [
        "# проверить разницу между преобразованием в 0..1 и -0.5..0.5\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KKzo7NK3uDrL",
        "outputId": "293f0e2b-afd1-476b-b0d6-fac183881180"
      },
      "source": [
        "# посмотрим на 10 случайных элементов картинок для тренировки\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in np.random.choice(len(x_train), 10, replace=False):\n",
        "  plt.figure(figsize=(3, 3))\n",
        "  plt.imshow(x_train[i].astype(\"uint8\"))\n",
        "  plt.title(fashion_dict[y_train[i]])\n",
        "  _ = plt.axis(\"off\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHwKznjqv8f4"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2fYmSoZtLv_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kaXFk9I9O-D",
        "outputId": "7d91e087-1aa4-4882-ca46-b8b919a8713c"
      },
      "source": [
        "# Параметры данных\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Масштабирование к 0..1\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Предобработка изображений\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# Преобразование входного формата\n",
        "train_images = x_train.reshape((-1, 784))\n",
        "test_images = x_test.reshape((-1, 784))\n",
        "\n",
        "# Получение метрик как списка\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohr2hzIm9q3Z",
        "outputId": "b445e8b8-149a-4e85-e6fe-ad01caa9e261"
      },
      "source": [
        "# Простая модель, как с урока\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(num_classes, activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 104,938\n",
            "Trainable params: 104,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etdnye6lAGh2"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daGOLyuD9zdd",
        "outputId": "cb6893de-3858-4779-ef5c-d952373c7a47"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(train_images, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8459 - accuracy: 0.7212 - val_loss: 0.4525 - val_accuracy: 0.8413\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4285 - accuracy: 0.8485 - val_loss: 0.4001 - val_accuracy: 0.8568\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3712 - accuracy: 0.8677 - val_loss: 0.3778 - val_accuracy: 0.8627\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3483 - accuracy: 0.8718 - val_loss: 0.3541 - val_accuracy: 0.8737\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3204 - accuracy: 0.8829 - val_loss: 0.3498 - val_accuracy: 0.8751\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3076 - accuracy: 0.8877 - val_loss: 0.3333 - val_accuracy: 0.8812\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2943 - accuracy: 0.8919 - val_loss: 0.3305 - val_accuracy: 0.8804\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2775 - accuracy: 0.8964 - val_loss: 0.3315 - val_accuracy: 0.8816\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2658 - accuracy: 0.9027 - val_loss: 0.3333 - val_accuracy: 0.8825\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2665 - accuracy: 0.9011 - val_loss: 0.3365 - val_accuracy: 0.8837\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2546 - accuracy: 0.9054 - val_loss: 0.3191 - val_accuracy: 0.8884\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2405 - accuracy: 0.9090 - val_loss: 0.3258 - val_accuracy: 0.8841\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2338 - accuracy: 0.9135 - val_loss: 0.3611 - val_accuracy: 0.8758\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2285 - accuracy: 0.9150 - val_loss: 0.3211 - val_accuracy: 0.8898\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2195 - accuracy: 0.9190 - val_loss: 0.3249 - val_accuracy: 0.8860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8e38191790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85UOqmB061_M",
        "outputId": "7e1b68c4-8e39-4918-e739-922d463c64fd"
      },
      "source": [
        "score = model.evaluate(test_images, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.35079655051231384\n",
            "Test accuracy: 0.8763999938964844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osnCGglG9x_h"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRjCUTre-JKw",
        "outputId": "6f308e24-eb8e-4bd2-c511-a1cf6c02db7e"
      },
      "source": [
        "score = model.evaluate(train_images, y_train, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.23346850275993347\n",
            "Test accuracy: 0.9141333103179932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLtDwLfa1M6k"
      },
      "source": [
        "План эксперимента 1.\n",
        "Соберём функцию, которая будет заполнять для нас статистику для сетей с разными параметрами и разными начальными весами (для усреднения аккуратности и вычисления дисперсии)\n",
        "\n",
        "12 моделей имеют два скрытых слоя, без учёта выходного, с разным количеством нейронов: (32, 16), (64, 16), (32, 32), (64,32), (128, 16), (128, 32), (128,64), (256, 32), (256, 64), (256, 128), (256, 256)\n",
        "\n",
        "Каждая сеть будет вычислена 10 раз, результаты сведены в таблицу.\n",
        "Функции активации, оптимайзер и функция потерь будут идентичны:\n",
        "для первого слоя - релу, для второго - сигмоида, для третьего - софтмакс\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd-GnhoS6cB5"
      },
      "source": [
        "from datetime import datetime\n",
        "from tensorflow.keras import initializers"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0jXlB0f4xlI"
      },
      "source": [
        "nets = (\"32-16\", \"64-16\", \"32-32\",\"64-32\", \"128-16\", \"128-32\", \"128-64\",\n",
        "        \"256-16\", \"256-32\",\"256-64\",\"256-128\",\"256-256\")\n",
        "test_1a_df = pd.DataFrame(columns=nets)\n",
        "test_1b_df = pd.DataFrame(columns=nets)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxAE4T0U6J-t"
      },
      "source": [
        "# test_1a_df.loc[0,\"32-16\"] = 1 # аккуратность для трейна\n",
        "# test_1b_df.loc[0,\"32-16\"] = 1 # аккуратность для теста"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIVKJ8x5_bdO"
      },
      "source": [
        "columns_1 = (\"name\", \"1st_layer_cnt\", \"2nd_layer_cnt\", \"acc_trn\", \"acc_tst\", \"acc_trn_disp\", \"acc_tst_disp\")\n",
        "models = pd.DataFrame(columns=columns_1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8LRVC7bFhWc"
      },
      "source": [
        "\n",
        "models.loc[0] = ([\"32-16\", 32, 16, 0,0,0,0])\n",
        "models.loc[1] = ([\"64-16\", 64, 16, 0,0,0,0])\n",
        "models.loc[2] = ([\"32-32\", 32, 32, 0,0,0,0])\n",
        "models.loc[3] = ([\"64-32\", 64, 32, 0,0,0,0])\n",
        "models.loc[4] = ([\"128-16\", 128, 16, 0,0,0,0])\n",
        "models.loc[5] = ([\"128-32\", 128, 32, 0,0,0,0])\n",
        "models.loc[6] = ([\"128-64\", 128, 64, 0,0,0,0])\n",
        "models.loc[7] = ([\"256-16\", 256, 16, 0,0,0,0])\n",
        "models.loc[8] = ([\"256-32\", 256, 32, 0,0,0,0])\n",
        "models.loc[9] = ([\"256-64\", 256, 64, 0,0,0,0])\n",
        "models.loc[10] = ([\"256-128\", 256, 128, 0,0,0,0])\n",
        "models.loc[11] = ([\"256-256\", 256, 256, 0,0,0,0])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "r9RNW4CPGU4w",
        "outputId": "7e444853-9acf-46cf-abea-867936af5ba8"
      },
      "source": [
        "models"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>1st_layer_cnt</th>\n",
              "      <th>2nd_layer_cnt</th>\n",
              "      <th>acc_trn</th>\n",
              "      <th>acc_tst</th>\n",
              "      <th>acc_trn_disp</th>\n",
              "      <th>acc_tst_disp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32-16</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>64-16</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32-32</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>64-32</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>128-16</td>\n",
              "      <td>128</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>128-32</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>128-64</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>256-16</td>\n",
              "      <td>256</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>256-32</td>\n",
              "      <td>256</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>256-64</td>\n",
              "      <td>256</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>256-128</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>256-256</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       name 1st_layer_cnt 2nd_layer_cnt  ... acc_tst acc_trn_disp acc_tst_disp\n",
              "0     32-16            32            16  ...       0            0            0\n",
              "1     64-16            64            16  ...       0            0            0\n",
              "2     32-32            32            32  ...       0            0            0\n",
              "3     64-32            64            32  ...       0            0            0\n",
              "4    128-16           128            16  ...       0            0            0\n",
              "5    128-32           128            32  ...       0            0            0\n",
              "6    128-64           128            64  ...       0            0            0\n",
              "7    256-16           256            16  ...       0            0            0\n",
              "8    256-32           256            32  ...       0            0            0\n",
              "9    256-64           256            64  ...       0            0            0\n",
              "10  256-128           256           128  ...       0            0            0\n",
              "11  256-256           256           256  ...       0            0            0\n",
              "\n",
              "[12 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-DIb22jANgx"
      },
      "source": [
        "for i in range(10):\n",
        "  for model in models.itertuples():\n",
        "    print(\"Обработка модели \", model[1], \"Итерация \", i)\n",
        "    model_1 = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(model[2], activation='relu', input_shape=(784,),\n",
        "                    kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                  stddev=0.15, \n",
        "                                      seed=int(datetime.now().timestamp()))),\n",
        "        layers.Dense(model[3], activation='sigmoid',\n",
        "                    kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                  stddev=0.15, \n",
        "                                      seed=int(datetime.now().timestamp()))),\n",
        "        layers.Dense(num_classes, activation=\"softmax\")\n",
        "    ]\n",
        "  )\n",
        "    model_1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    model_1.fit(train_images, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "    test_1a_df.loc[i, model[1]] =  model_1.evaluate(train_images, y_train, verbose=0)[1] # аккуратность для трейна\n",
        "    test_1b_df.loc[i, model[1]] = model_1.evaluate(test_images, y_test, verbose=0)[1] # аккуратность для теста\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "OfK0pxEHKiYJ",
        "outputId": "e4feea3d-483d-4abc-dab5-46653b780542"
      },
      "source": [
        "test_1b_df"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>32-16</th>\n",
              "      <th>64-16</th>\n",
              "      <th>32-32</th>\n",
              "      <th>64-32</th>\n",
              "      <th>128-16</th>\n",
              "      <th>128-32</th>\n",
              "      <th>128-64</th>\n",
              "      <th>256-16</th>\n",
              "      <th>256-32</th>\n",
              "      <th>256-64</th>\n",
              "      <th>256-128</th>\n",
              "      <th>256-256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.865</td>\n",
              "      <td>0.8671</td>\n",
              "      <td>0.8681</td>\n",
              "      <td>0.8759</td>\n",
              "      <td>0.8759</td>\n",
              "      <td>0.8772</td>\n",
              "      <td>0.8807</td>\n",
              "      <td>0.8851</td>\n",
              "      <td>0.8806</td>\n",
              "      <td>0.8829</td>\n",
              "      <td>0.8841</td>\n",
              "      <td>0.8868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.8622</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8636</td>\n",
              "      <td>0.8717</td>\n",
              "      <td>0.8806</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.8826</td>\n",
              "      <td>0.8841</td>\n",
              "      <td>0.8819</td>\n",
              "      <td>0.8816</td>\n",
              "      <td>0.8854</td>\n",
              "      <td>0.8885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8685</td>\n",
              "      <td>0.8719</td>\n",
              "      <td>0.8647</td>\n",
              "      <td>0.8777</td>\n",
              "      <td>0.8782</td>\n",
              "      <td>0.8801</td>\n",
              "      <td>0.8783</td>\n",
              "      <td>0.8765</td>\n",
              "      <td>0.8826</td>\n",
              "      <td>0.8844</td>\n",
              "      <td>0.8922</td>\n",
              "      <td>0.8812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.8622</td>\n",
              "      <td>0.8699</td>\n",
              "      <td>0.8656</td>\n",
              "      <td>0.8765</td>\n",
              "      <td>0.8807</td>\n",
              "      <td>0.8821</td>\n",
              "      <td>0.8812</td>\n",
              "      <td>0.8826</td>\n",
              "      <td>0.8791</td>\n",
              "      <td>0.8851</td>\n",
              "      <td>0.8838</td>\n",
              "      <td>0.8854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.8632</td>\n",
              "      <td>0.8699</td>\n",
              "      <td>0.8665</td>\n",
              "      <td>0.8721</td>\n",
              "      <td>0.8811</td>\n",
              "      <td>0.8769</td>\n",
              "      <td>0.8804</td>\n",
              "      <td>0.8782</td>\n",
              "      <td>0.8761</td>\n",
              "      <td>0.8853</td>\n",
              "      <td>0.8859</td>\n",
              "      <td>0.8911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.8645</td>\n",
              "      <td>0.8732</td>\n",
              "      <td>0.8691</td>\n",
              "      <td>0.877</td>\n",
              "      <td>0.881</td>\n",
              "      <td>0.8812</td>\n",
              "      <td>0.8791</td>\n",
              "      <td>0.8741</td>\n",
              "      <td>0.8851</td>\n",
              "      <td>0.8863</td>\n",
              "      <td>0.8891</td>\n",
              "      <td>0.8825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.8608</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8704</td>\n",
              "      <td>0.8751</td>\n",
              "      <td>0.8758</td>\n",
              "      <td>0.8793</td>\n",
              "      <td>0.8851</td>\n",
              "      <td>0.8801</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8804</td>\n",
              "      <td>0.8895</td>\n",
              "      <td>0.8881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.8675</td>\n",
              "      <td>0.8699</td>\n",
              "      <td>0.8657</td>\n",
              "      <td>0.8767</td>\n",
              "      <td>0.8817</td>\n",
              "      <td>0.8777</td>\n",
              "      <td>0.8792</td>\n",
              "      <td>0.8844</td>\n",
              "      <td>0.8839</td>\n",
              "      <td>0.8878</td>\n",
              "      <td>0.883</td>\n",
              "      <td>0.8878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.8688</td>\n",
              "      <td>0.8725</td>\n",
              "      <td>0.8699</td>\n",
              "      <td>0.8735</td>\n",
              "      <td>0.8734</td>\n",
              "      <td>0.8804</td>\n",
              "      <td>0.8832</td>\n",
              "      <td>0.881</td>\n",
              "      <td>0.8829</td>\n",
              "      <td>0.8899</td>\n",
              "      <td>0.8857</td>\n",
              "      <td>0.891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.8617</td>\n",
              "      <td>0.8714</td>\n",
              "      <td>0.8678</td>\n",
              "      <td>0.8787</td>\n",
              "      <td>0.8806</td>\n",
              "      <td>0.8817</td>\n",
              "      <td>0.8808</td>\n",
              "      <td>0.8803</td>\n",
              "      <td>0.8829</td>\n",
              "      <td>0.8884</td>\n",
              "      <td>0.8845</td>\n",
              "      <td>0.881</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    32-16   64-16   32-32   64-32  ...  256-32  256-64 256-128 256-256\n",
              "0   0.865  0.8671  0.8681  0.8759  ...  0.8806  0.8829  0.8841  0.8868\n",
              "1  0.8622  0.8711  0.8636  0.8717  ...  0.8819  0.8816  0.8854  0.8885\n",
              "2  0.8685  0.8719  0.8647  0.8777  ...  0.8826  0.8844  0.8922  0.8812\n",
              "3  0.8622  0.8699  0.8656  0.8765  ...  0.8791  0.8851  0.8838  0.8854\n",
              "4  0.8632  0.8699  0.8665  0.8721  ...  0.8761  0.8853  0.8859  0.8911\n",
              "5  0.8645  0.8732  0.8691   0.877  ...  0.8851  0.8863  0.8891  0.8825\n",
              "6  0.8608  0.8711  0.8704  0.8751  ...  0.8874  0.8804  0.8895  0.8881\n",
              "7  0.8675  0.8699  0.8657  0.8767  ...  0.8839  0.8878   0.883  0.8878\n",
              "8  0.8688  0.8725  0.8699  0.8735  ...  0.8829  0.8899  0.8857   0.891\n",
              "9  0.8617  0.8714  0.8678  0.8787  ...  0.8829  0.8884  0.8845   0.881\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "eO-rf44mOxll",
        "outputId": "95b56f8f-c779-4310-8976-da768f1f421a"
      },
      "source": [
        "test_1a_df"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>32-16</th>\n",
              "      <th>64-16</th>\n",
              "      <th>32-32</th>\n",
              "      <th>64-32</th>\n",
              "      <th>128-16</th>\n",
              "      <th>128-32</th>\n",
              "      <th>128-64</th>\n",
              "      <th>256-16</th>\n",
              "      <th>256-32</th>\n",
              "      <th>256-64</th>\n",
              "      <th>256-128</th>\n",
              "      <th>256-256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.889433</td>\n",
              "      <td>0.897717</td>\n",
              "      <td>0.891167</td>\n",
              "      <td>0.90525</td>\n",
              "      <td>0.912467</td>\n",
              "      <td>0.916217</td>\n",
              "      <td>0.919617</td>\n",
              "      <td>0.920867</td>\n",
              "      <td>0.919933</td>\n",
              "      <td>0.92655</td>\n",
              "      <td>0.927933</td>\n",
              "      <td>0.933783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.884117</td>\n",
              "      <td>0.900783</td>\n",
              "      <td>0.8877</td>\n",
              "      <td>0.898967</td>\n",
              "      <td>0.914433</td>\n",
              "      <td>0.918183</td>\n",
              "      <td>0.91755</td>\n",
              "      <td>0.924283</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.92495</td>\n",
              "      <td>0.92625</td>\n",
              "      <td>0.937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.889617</td>\n",
              "      <td>0.899417</td>\n",
              "      <td>0.888183</td>\n",
              "      <td>0.902583</td>\n",
              "      <td>0.910717</td>\n",
              "      <td>0.916383</td>\n",
              "      <td>0.9175</td>\n",
              "      <td>0.916717</td>\n",
              "      <td>0.923533</td>\n",
              "      <td>0.9272</td>\n",
              "      <td>0.93655</td>\n",
              "      <td>0.9252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.888467</td>\n",
              "      <td>0.90085</td>\n",
              "      <td>0.890317</td>\n",
              "      <td>0.905517</td>\n",
              "      <td>0.912167</td>\n",
              "      <td>0.916317</td>\n",
              "      <td>0.9176</td>\n",
              "      <td>0.923417</td>\n",
              "      <td>0.91835</td>\n",
              "      <td>0.92965</td>\n",
              "      <td>0.92525</td>\n",
              "      <td>0.935217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.88495</td>\n",
              "      <td>0.897483</td>\n",
              "      <td>0.891283</td>\n",
              "      <td>0.9018</td>\n",
              "      <td>0.913767</td>\n",
              "      <td>0.91325</td>\n",
              "      <td>0.91945</td>\n",
              "      <td>0.917683</td>\n",
              "      <td>0.919533</td>\n",
              "      <td>0.927967</td>\n",
              "      <td>0.92955</td>\n",
              "      <td>0.937317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.888933</td>\n",
              "      <td>0.900817</td>\n",
              "      <td>0.891883</td>\n",
              "      <td>0.902333</td>\n",
              "      <td>0.914167</td>\n",
              "      <td>0.91615</td>\n",
              "      <td>0.912317</td>\n",
              "      <td>0.911683</td>\n",
              "      <td>0.9255</td>\n",
              "      <td>0.92825</td>\n",
              "      <td>0.93565</td>\n",
              "      <td>0.933183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.883383</td>\n",
              "      <td>0.9003</td>\n",
              "      <td>0.893533</td>\n",
              "      <td>0.90375</td>\n",
              "      <td>0.9094</td>\n",
              "      <td>0.915667</td>\n",
              "      <td>0.922483</td>\n",
              "      <td>0.918533</td>\n",
              "      <td>0.9256</td>\n",
              "      <td>0.922333</td>\n",
              "      <td>0.93385</td>\n",
              "      <td>0.9365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.892883</td>\n",
              "      <td>0.895483</td>\n",
              "      <td>0.8901</td>\n",
              "      <td>0.90255</td>\n",
              "      <td>0.91785</td>\n",
              "      <td>0.915483</td>\n",
              "      <td>0.916117</td>\n",
              "      <td>0.9206</td>\n",
              "      <td>0.92345</td>\n",
              "      <td>0.928917</td>\n",
              "      <td>0.931767</td>\n",
              "      <td>0.939217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.8912</td>\n",
              "      <td>0.899417</td>\n",
              "      <td>0.893183</td>\n",
              "      <td>0.9035</td>\n",
              "      <td>0.90805</td>\n",
              "      <td>0.914967</td>\n",
              "      <td>0.9195</td>\n",
              "      <td>0.91805</td>\n",
              "      <td>0.925317</td>\n",
              "      <td>0.931733</td>\n",
              "      <td>0.931467</td>\n",
              "      <td>0.94025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.886017</td>\n",
              "      <td>0.902333</td>\n",
              "      <td>0.893517</td>\n",
              "      <td>0.907533</td>\n",
              "      <td>0.913533</td>\n",
              "      <td>0.914917</td>\n",
              "      <td>0.9191</td>\n",
              "      <td>0.91895</td>\n",
              "      <td>0.927367</td>\n",
              "      <td>0.93085</td>\n",
              "      <td>0.92795</td>\n",
              "      <td>0.9296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      32-16     64-16     32-32  ...    256-64   256-128   256-256\n",
              "0  0.889433  0.897717  0.891167  ...   0.92655  0.927933  0.933783\n",
              "1  0.884117  0.900783    0.8877  ...   0.92495   0.92625     0.937\n",
              "2  0.889617  0.899417  0.888183  ...    0.9272   0.93655    0.9252\n",
              "3  0.888467   0.90085  0.890317  ...   0.92965   0.92525  0.935217\n",
              "4   0.88495  0.897483  0.891283  ...  0.927967   0.92955  0.937317\n",
              "5  0.888933  0.900817  0.891883  ...   0.92825   0.93565  0.933183\n",
              "6  0.883383    0.9003  0.893533  ...  0.922333   0.93385    0.9365\n",
              "7  0.892883  0.895483    0.8901  ...  0.928917  0.931767  0.939217\n",
              "8    0.8912  0.899417  0.893183  ...  0.931733  0.931467   0.94025\n",
              "9  0.886017  0.902333  0.893517  ...   0.93085   0.92795    0.9296\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEEBBmA2kQHY"
      },
      "source": [
        "models[\"acc_trn\"] = test_1a_df.astype(np.float64).describe().T[\"mean\"].values\n",
        "models[\"acc_trn_disp\"] = test_1a_df.astype(np.float64).describe().T[\"std\"].values\n",
        "models[\"acc_tst\"] = test_1b_df.astype(np.float64).describe().T[\"mean\"].values\n",
        "models[\"acc_tst_disp\"] = test_1b_df.astype(np.float64).describe().T[\"std\"].values"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "lYVwcb4NmAqw",
        "outputId": "6f642d1c-1ddf-4d5f-e877-c2d37ea86e9e"
      },
      "source": [
        "models"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>1st_layer_cnt</th>\n",
              "      <th>2nd_layer_cnt</th>\n",
              "      <th>acc_trn</th>\n",
              "      <th>acc_tst</th>\n",
              "      <th>acc_trn_disp</th>\n",
              "      <th>acc_tst_disp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32-16</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.887900</td>\n",
              "      <td>0.86444</td>\n",
              "      <td>0.003151</td>\n",
              "      <td>0.002935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>64-16</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.899460</td>\n",
              "      <td>0.87080</td>\n",
              "      <td>0.002034</td>\n",
              "      <td>0.001717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32-32</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>0.891087</td>\n",
              "      <td>0.86714</td>\n",
              "      <td>0.002066</td>\n",
              "      <td>0.002280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>64-32</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>0.903378</td>\n",
              "      <td>0.87549</td>\n",
              "      <td>0.002354</td>\n",
              "      <td>0.002359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>128-16</td>\n",
              "      <td>128</td>\n",
              "      <td>16</td>\n",
              "      <td>0.912655</td>\n",
              "      <td>0.87890</td>\n",
              "      <td>0.002794</td>\n",
              "      <td>0.002896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>128-32</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>0.915753</td>\n",
              "      <td>0.87980</td>\n",
              "      <td>0.001276</td>\n",
              "      <td>0.001935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>128-64</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.918123</td>\n",
              "      <td>0.88106</td>\n",
              "      <td>0.002679</td>\n",
              "      <td>0.002077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>256-16</td>\n",
              "      <td>256</td>\n",
              "      <td>16</td>\n",
              "      <td>0.919078</td>\n",
              "      <td>0.88064</td>\n",
              "      <td>0.003575</td>\n",
              "      <td>0.003594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>256-32</td>\n",
              "      <td>256</td>\n",
              "      <td>32</td>\n",
              "      <td>0.923358</td>\n",
              "      <td>0.88225</td>\n",
              "      <td>0.003049</td>\n",
              "      <td>0.003143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>256-64</td>\n",
              "      <td>256</td>\n",
              "      <td>64</td>\n",
              "      <td>0.927840</td>\n",
              "      <td>0.88521</td>\n",
              "      <td>0.002781</td>\n",
              "      <td>0.003023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>256-128</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>0.930622</td>\n",
              "      <td>0.88632</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>0.002971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>256-256</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>0.934727</td>\n",
              "      <td>0.88634</td>\n",
              "      <td>0.004549</td>\n",
              "      <td>0.003727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       name 1st_layer_cnt 2nd_layer_cnt  ...  acc_tst  acc_trn_disp  acc_tst_disp\n",
              "0     32-16            32            16  ...  0.86444      0.003151      0.002935\n",
              "1     64-16            64            16  ...  0.87080      0.002034      0.001717\n",
              "2     32-32            32            32  ...  0.86714      0.002066      0.002280\n",
              "3     64-32            64            32  ...  0.87549      0.002354      0.002359\n",
              "4    128-16           128            16  ...  0.87890      0.002794      0.002896\n",
              "5    128-32           128            32  ...  0.87980      0.001276      0.001935\n",
              "6    128-64           128            64  ...  0.88106      0.002679      0.002077\n",
              "7    256-16           256            16  ...  0.88064      0.003575      0.003594\n",
              "8    256-32           256            32  ...  0.88225      0.003049      0.003143\n",
              "9    256-64           256            64  ...  0.88521      0.002781      0.003023\n",
              "10  256-128           256           128  ...  0.88632      0.003892      0.002971\n",
              "11  256-256           256           256  ...  0.88634      0.004549      0.003727\n",
              "\n",
              "[12 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb1OgFDDoVG-"
      },
      "source": [
        "На тесте у всех моделей примерно одинаковые средние значения аккуратности. Поэтому посмотрим на разброс.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "b9q2ruErnorH",
        "outputId": "88bcbbce-5fcd-4f31-e34b-d0ee20a18cea"
      },
      "source": [
        "models.sort_values(by=['acc_tst_disp', 'acc_trn_disp'], ascending=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>1st_layer_cnt</th>\n",
              "      <th>2nd_layer_cnt</th>\n",
              "      <th>acc_trn</th>\n",
              "      <th>acc_tst</th>\n",
              "      <th>acc_trn_disp</th>\n",
              "      <th>acc_tst_disp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>64-16</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.899460</td>\n",
              "      <td>0.87080</td>\n",
              "      <td>0.002034</td>\n",
              "      <td>0.001717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>128-32</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>0.915753</td>\n",
              "      <td>0.87980</td>\n",
              "      <td>0.001276</td>\n",
              "      <td>0.001935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>128-64</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.918123</td>\n",
              "      <td>0.88106</td>\n",
              "      <td>0.002679</td>\n",
              "      <td>0.002077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32-32</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>0.891087</td>\n",
              "      <td>0.86714</td>\n",
              "      <td>0.002066</td>\n",
              "      <td>0.002280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>64-32</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>0.903378</td>\n",
              "      <td>0.87549</td>\n",
              "      <td>0.002354</td>\n",
              "      <td>0.002359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>128-16</td>\n",
              "      <td>128</td>\n",
              "      <td>16</td>\n",
              "      <td>0.912655</td>\n",
              "      <td>0.87890</td>\n",
              "      <td>0.002794</td>\n",
              "      <td>0.002896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32-16</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.887900</td>\n",
              "      <td>0.86444</td>\n",
              "      <td>0.003151</td>\n",
              "      <td>0.002935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>256-128</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>0.930622</td>\n",
              "      <td>0.88632</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>0.002971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>256-64</td>\n",
              "      <td>256</td>\n",
              "      <td>64</td>\n",
              "      <td>0.927840</td>\n",
              "      <td>0.88521</td>\n",
              "      <td>0.002781</td>\n",
              "      <td>0.003023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>256-32</td>\n",
              "      <td>256</td>\n",
              "      <td>32</td>\n",
              "      <td>0.923358</td>\n",
              "      <td>0.88225</td>\n",
              "      <td>0.003049</td>\n",
              "      <td>0.003143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>256-16</td>\n",
              "      <td>256</td>\n",
              "      <td>16</td>\n",
              "      <td>0.919078</td>\n",
              "      <td>0.88064</td>\n",
              "      <td>0.003575</td>\n",
              "      <td>0.003594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>256-256</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>0.934727</td>\n",
              "      <td>0.88634</td>\n",
              "      <td>0.004549</td>\n",
              "      <td>0.003727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       name 1st_layer_cnt 2nd_layer_cnt  ...  acc_tst  acc_trn_disp  acc_tst_disp\n",
              "1     64-16            64            16  ...  0.87080      0.002034      0.001717\n",
              "5    128-32           128            32  ...  0.87980      0.001276      0.001935\n",
              "6    128-64           128            64  ...  0.88106      0.002679      0.002077\n",
              "2     32-32            32            32  ...  0.86714      0.002066      0.002280\n",
              "3     64-32            64            32  ...  0.87549      0.002354      0.002359\n",
              "4    128-16           128            16  ...  0.87890      0.002794      0.002896\n",
              "0     32-16            32            16  ...  0.86444      0.003151      0.002935\n",
              "10  256-128           256           128  ...  0.88632      0.003892      0.002971\n",
              "9    256-64           256            64  ...  0.88521      0.002781      0.003023\n",
              "8    256-32           256            32  ...  0.88225      0.003049      0.003143\n",
              "7    256-16           256            16  ...  0.88064      0.003575      0.003594\n",
              "11  256-256           256           256  ...  0.88634      0.004549      0.003727\n",
              "\n",
              "[12 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF6DUYfpn9YI"
      },
      "source": [
        "Модель 64-16 имеет наименьший разброс на тесте, что может говорить о большей устойчивости модели при обучении с разными стартовыми весами. Также значения аккуратности на тесте и на трейне примерно одинаковые, можно сделать вывод о том, что модель не плохо обобщает, а не старается \"подстроиться\" под тест. В противовес можно выделить модель 256-256. Она имеет большую разницу аккуратности на трейне и тесте, кроме того, высокий разброс \"аккуратностей\". Я бы предположил, что такая модель склонна переобучаться и её адекватность сильно зависит от стартовых условий. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJmfDLaAp9Ix"
      },
      "source": [
        "nets2 = (\"128-64-32\", \"64-64-32-32-32\", \"64-64-64-64-64-64-64-64-64\",\n",
        "         \"256-256-256-256-256-256-256-256-256-256\")\n",
        "test_2a_df = pd.DataFrame(columns=nets2)\n",
        "test_2b_df = pd.DataFrame(columns=nets2)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeJO_4j5rCXR"
      },
      "source": [
        "Список моделей для экспеориментов в переменной nets2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsN-LOUhqkuY"
      },
      "source": [
        "for i in range(10):\n",
        "  model_21_name = nets2[0]\n",
        "  print(\"Работает модель \", model_21_name, \" Итерация \", i)\n",
        "  model_21 = keras.Sequential(\n",
        "  [\n",
        "      layers.Dense(128, activation='relu', input_shape=(784,),\n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(64, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(32, activation='relu',\n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(num_classes, activation=\"softmax\")\n",
        "  ]\n",
        "  )\n",
        "\n",
        "  model_21.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  model_21.fit(train_images, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "  test_2a_df.loc[i, model_21_name] =  model_21.evaluate(train_images, y_train, verbose=0)[1] # аккуратность для трейна\n",
        "  test_2b_df.loc[i, model_21_name] = model_21.evaluate(test_images, y_test, verbose=0)[1] # аккуратность для теста\n",
        "\n",
        "\n",
        "  model_22_name = nets2[1]\n",
        "  print(\"Работает модель \", model_22_name, \" Итерация \", i)\n",
        "  model_22 = keras.Sequential(\n",
        "  [\n",
        "      layers.Dense(64, activation='relu', input_shape=(784,),\n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(64, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),      \n",
        "      layers.Dense(32, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(32, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(32, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(num_classes, activation=\"softmax\")\n",
        "  ]\n",
        "  )\n",
        "\n",
        "  model_22.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  model_22.fit(train_images, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "  test_2a_df.loc[i, model_22_name] =  model_22.evaluate(train_images, y_train, verbose=0)[1] # аккуратность для трейна\n",
        "  test_2b_df.loc[i, model_22_name] = model_22.evaluate(test_images, y_test, verbose=0)[1] # аккуратность для теста\n",
        "\n",
        "  model_23_name = nets2[2]\n",
        "  print(\"Работает модель \", model_23_name, \" Итерация \", i)\n",
        "  model_23 = keras.Sequential(\n",
        "  [\n",
        "      layers.Dense(64, activation='relu', input_shape=(784,),\n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(64, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),      \n",
        "      layers.Dense(64, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(64, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(64, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "        layers.Dense(64, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),      \n",
        "      layers.Dense(64, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(64, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(64, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(num_classes, activation=\"softmax\")\n",
        "  ]\n",
        "  )\n",
        "\n",
        "  model_23.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  model_23.fit(train_images, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "  test_2a_df.loc[i, model_23_name] =  model_23.evaluate(train_images, y_train, verbose=0)[1] # аккуратность для трейна\n",
        "  test_2b_df.loc[i, model_23_name] = model_23.evaluate(test_images, y_test, verbose=0)[1] # аккуратность для теста\n",
        "\n",
        "  model_24_name = nets2[3]\n",
        "  print(\"Работает модель \", model_24_name, \" Итерация \", i)\n",
        "  model_24 = keras.Sequential(\n",
        "  [\n",
        "      layers.Dense(256, activation='relu', input_shape=(784,),\n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(256, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),      \n",
        "      layers.Dense(256, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(256, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(256, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "        layers.Dense(256, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),      \n",
        "      layers.Dense(256, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(256, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(256, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(256, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(num_classes, activation=\"softmax\")\n",
        "  ]\n",
        "  )\n",
        "\n",
        "  model_24.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  model_24.fit(train_images, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "  test_2a_df.loc[i, model_24_name] =  model_24.evaluate(train_images, y_train, verbose=0)[1] # аккуратность для трейна\n",
        "  test_2b_df.loc[i, model_24_name] = model_24.evaluate(test_images, y_test, verbose=0)[1] # аккуратность для теста\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Fl5YFFHD23Lt",
        "outputId": "8f976f6e-0867-4ea2-ea98-398a27dbe3ae"
      },
      "source": [
        "test_2a_df.astype(np.float64).describe()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>128-64-32</th>\n",
              "      <th>64-64-32-32-32</th>\n",
              "      <th>64-64-64-64-64-64-64-64-64</th>\n",
              "      <th>256-256-256-256-256-256-256-256-256-256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.920207</td>\n",
              "      <td>0.906727</td>\n",
              "      <td>0.904048</td>\n",
              "      <td>0.890135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.002295</td>\n",
              "      <td>0.004205</td>\n",
              "      <td>0.003335</td>\n",
              "      <td>0.005171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.915967</td>\n",
              "      <td>0.899900</td>\n",
              "      <td>0.899250</td>\n",
              "      <td>0.881283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.919275</td>\n",
              "      <td>0.904433</td>\n",
              "      <td>0.902058</td>\n",
              "      <td>0.887638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.920142</td>\n",
              "      <td>0.907467</td>\n",
              "      <td>0.904400</td>\n",
              "      <td>0.889008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.921196</td>\n",
              "      <td>0.909713</td>\n",
              "      <td>0.905458</td>\n",
              "      <td>0.892508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.924700</td>\n",
              "      <td>0.912933</td>\n",
              "      <td>0.909683</td>\n",
              "      <td>0.898217</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       128-64-32  ...  256-256-256-256-256-256-256-256-256-256\n",
              "count  10.000000  ...                                10.000000\n",
              "mean    0.920207  ...                                 0.890135\n",
              "std     0.002295  ...                                 0.005171\n",
              "min     0.915967  ...                                 0.881283\n",
              "25%     0.919275  ...                                 0.887638\n",
              "50%     0.920142  ...                                 0.889008\n",
              "75%     0.921196  ...                                 0.892508\n",
              "max     0.924700  ...                                 0.898217\n",
              "\n",
              "[8 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "VFdTDMiX28zZ",
        "outputId": "897061a0-0894-45de-a1bb-312cfff76997"
      },
      "source": [
        "test_2b_df.astype(np.float64).describe()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>128-64-32</th>\n",
              "      <th>64-64-32-32-32</th>\n",
              "      <th>64-64-64-64-64-64-64-64-64</th>\n",
              "      <th>256-256-256-256-256-256-256-256-256-256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.878810</td>\n",
              "      <td>0.873350</td>\n",
              "      <td>0.870820</td>\n",
              "      <td>0.859080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.002506</td>\n",
              "      <td>0.002867</td>\n",
              "      <td>0.003082</td>\n",
              "      <td>0.004953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.875200</td>\n",
              "      <td>0.869000</td>\n",
              "      <td>0.864900</td>\n",
              "      <td>0.848500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.877325</td>\n",
              "      <td>0.871475</td>\n",
              "      <td>0.869575</td>\n",
              "      <td>0.857025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.878950</td>\n",
              "      <td>0.872650</td>\n",
              "      <td>0.870500</td>\n",
              "      <td>0.859900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.880475</td>\n",
              "      <td>0.875175</td>\n",
              "      <td>0.872675</td>\n",
              "      <td>0.862600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.883100</td>\n",
              "      <td>0.878100</td>\n",
              "      <td>0.875900</td>\n",
              "      <td>0.865300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       128-64-32  ...  256-256-256-256-256-256-256-256-256-256\n",
              "count  10.000000  ...                                10.000000\n",
              "mean    0.878810  ...                                 0.859080\n",
              "std     0.002506  ...                                 0.004953\n",
              "min     0.875200  ...                                 0.848500\n",
              "25%     0.877325  ...                                 0.857025\n",
              "50%     0.878950  ...                                 0.859900\n",
              "75%     0.880475  ...                                 0.862600\n",
              "max     0.883100  ...                                 0.865300\n",
              "\n",
              "[8 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np19vKuz70rK"
      },
      "source": [
        "В случае глубоких ИНС ситуация примерно одинаковая - относительно низки разброс и значения аккуратности на тестовой выборке ниже, чем на тренировочной. К сожалению, однозначно интерпретировать результаты я не могу, очевидно, имеет смысл поработать ещё и с типом активации и т.п. Для каждого типа задачи свой вид ИНС подходит лучшим образом.\n",
        "\n",
        "**Если смотреть на разброс аккуратности, видно, что с ростом числа слоёв и количества нейронов в слое разброс увеличивается. Рискну предположить, что это происходит из-за того, что при большом числе параметров бОльшее число минимумов функции потерь, в которые попадают сети при разных начальных условиях**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spYiyCbSB9q2"
      },
      "source": [
        "Хорошие результаты из всех сетей получились у сети \"128-32\" и \"128-64-32\". Эти сети я выбрал, чтобы попытаться улучшить результаты изменением классификатора."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARNd7jcwCmZA"
      },
      "source": [
        "nets3 = (\"128-64-32a\", \"128-32a\",\"128-64-32sgd\", \"128-32sgd\", \"128-64-32rms\", \"128-32rms\")\n",
        "test_3a_df = pd.DataFrame(columns=nets3)\n",
        "test_3b_df = pd.DataFrame(columns=nets3)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJYRAfJsCXlk",
        "outputId": "0f1bc70c-4a79-4e26-c7f3-20ed204382b1"
      },
      "source": [
        "for i in range(10):\n",
        "  best_model_1_name = nets3[0]\n",
        "  print(\"Работает модель \", best_model_1_name, \" Итерация \", i)\n",
        "  best_model_1 = keras.Sequential(\n",
        "  [\n",
        "      layers.Dense(128, activation='relu', input_shape=(784,),\n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(64, activation='relu', \n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(32, activation='relu',\n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(num_classes, activation=\"softmax\")\n",
        "  ]\n",
        "  )\n",
        "\n",
        "  best_model_1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  best_model_1.fit(train_images, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "  test_3a_df.loc[i, best_model_1_name] =  best_model_1.evaluate(train_images, y_train, verbose=0)[1] # аккуратность для трейна\n",
        "  test_3b_df.loc[i, best_model_1_name] = best_model_1.evaluate(test_images, y_test, verbose=0)[1] # аккуратность для теста\n",
        "\n",
        "  best_model_2_name = nets3[1]\n",
        "  print(\"Работает модель \", best_model_1_name, \" Итерация \", i)\n",
        "  best_model_2 = keras.Sequential(\n",
        "  [\n",
        "      layers.Dense(128, activation='relu', input_shape=(784,),\n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(32, activation='sigmoid',\n",
        "                  kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                                stddev=0.15, \n",
        "                                    seed=int(datetime.now().timestamp()))),\n",
        "      layers.Dense(num_classes, activation=\"softmax\")\n",
        "  ]\n",
        "  )\n",
        "\n",
        "  best_model_2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  best_model_2.fit(train_images, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "  test_3a_df.loc[i, best_model_2_name] =  best_model_2.evaluate(train_images, y_train, verbose=0)[1] # аккуратность для трейна\n",
        "  test_3b_df.loc[i, best_model_2_name] = best_model_2.evaluate(test_images, y_test, verbose=0)[1] # аккуратность для теста\n",
        "\n",
        "  best_model_1_name = nets3[2]\n",
        "  print(\"Работает модель \", best_model_1_name, \" Итерация \", i)\n",
        "\n",
        "  best_model_1.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "  best_model_1.fit(train_images, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "  test_3a_df.loc[i, best_model_1_name] =  best_model_1.evaluate(train_images, y_train, verbose=0)[1] # аккуратность для трейна\n",
        "  test_3b_df.loc[i, best_model_1_name] = best_model_1.evaluate(test_images, y_test, verbose=0)[1] # аккуратность для теста\n",
        "\n",
        "  best_model_2_name = nets3[3]\n",
        "  print(\"Работает модель \", best_model_2_name, \" Итерация \", i)\n",
        "\n",
        "  best_model_2.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "  best_model_2.fit(train_images, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "  test_3a_df.loc[i, best_model_2_name] =  best_model_2.evaluate(train_images, y_train, verbose=0)[1] # аккуратность для трейна\n",
        "  test_3b_df.loc[i, best_model_2_name] = best_model_2.evaluate(test_images, y_test, verbose=0)[1] # аккуратность для теста\n",
        "\n",
        "  best_model_1_name = nets3[4]\n",
        "  print(\"Работает модель \", best_model_1_name, \" Итерация \", i)\n",
        "\n",
        "  best_model_1.compile(loss=\"categorical_crossentropy\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
        "  best_model_1.fit(train_images, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "  test_3a_df.loc[i, best_model_1_name] =  best_model_1.evaluate(train_images, y_train, verbose=0)[1] # аккуратность для трейна\n",
        "  test_3b_df.loc[i, best_model_1_name] = best_model_1.evaluate(test_images, y_test, verbose=0)[1] # аккуратность для теста\n",
        "\n",
        "  best_model_2_name = nets3[5]\n",
        "  print(\"Работает модель \", best_model_2_name, \" Итерация \", i)\n",
        "\n",
        "  best_model_2.compile(loss=\"categorical_crossentropy\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
        "  best_model_2.fit(train_images, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "  test_3a_df.loc[i, best_model_2_name] =  best_model_2.evaluate(train_images, y_train, verbose=0)[1] # аккуратность для трейна\n",
        "  test_3b_df.loc[i, best_model_2_name] = best_model_2.evaluate(test_images, y_test, verbose=0)[1] # аккуратность для теста"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Работает модель  128-64-32a  Итерация  0\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 0.8435 - accuracy: 0.7069 - val_loss: 0.4367 - val_accuracy: 0.8443\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4221 - accuracy: 0.8498 - val_loss: 0.4068 - val_accuracy: 0.8522\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3723 - accuracy: 0.8655 - val_loss: 0.3626 - val_accuracy: 0.8691\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3315 - accuracy: 0.8803 - val_loss: 0.3993 - val_accuracy: 0.8534\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3188 - accuracy: 0.8845 - val_loss: 0.3612 - val_accuracy: 0.8689\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3069 - accuracy: 0.8862 - val_loss: 0.3566 - val_accuracy: 0.8723\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2832 - accuracy: 0.8953 - val_loss: 0.3347 - val_accuracy: 0.8786\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2751 - accuracy: 0.8986 - val_loss: 0.3418 - val_accuracy: 0.8768\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2588 - accuracy: 0.9020 - val_loss: 0.3267 - val_accuracy: 0.8852\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2433 - accuracy: 0.9118 - val_loss: 0.3291 - val_accuracy: 0.8837\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2443 - accuracy: 0.9086 - val_loss: 0.3436 - val_accuracy: 0.8802\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2293 - accuracy: 0.9141 - val_loss: 0.3338 - val_accuracy: 0.8855\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2178 - accuracy: 0.9186 - val_loss: 0.3411 - val_accuracy: 0.8879\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2154 - accuracy: 0.9205 - val_loss: 0.3213 - val_accuracy: 0.8889\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2107 - accuracy: 0.9210 - val_loss: 0.3551 - val_accuracy: 0.8822\n",
            "Работает модель  128-64-32a  Итерация  0\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2753 - accuracy: 0.6377 - val_loss: 0.5471 - val_accuracy: 0.8239\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4964 - accuracy: 0.8416 - val_loss: 0.4382 - val_accuracy: 0.8518\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4102 - accuracy: 0.8591 - val_loss: 0.3850 - val_accuracy: 0.8645\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3658 - accuracy: 0.8717 - val_loss: 0.3695 - val_accuracy: 0.8674\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3428 - accuracy: 0.8765 - val_loss: 0.3531 - val_accuracy: 0.8736\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3170 - accuracy: 0.8870 - val_loss: 0.3432 - val_accuracy: 0.8762\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3017 - accuracy: 0.8912 - val_loss: 0.3421 - val_accuracy: 0.8793\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2896 - accuracy: 0.8970 - val_loss: 0.3300 - val_accuracy: 0.8810\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.8998 - val_loss: 0.3394 - val_accuracy: 0.8801\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2638 - accuracy: 0.9045 - val_loss: 0.3272 - val_accuracy: 0.8792\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2514 - accuracy: 0.9091 - val_loss: 0.3163 - val_accuracy: 0.8863\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2493 - accuracy: 0.9090 - val_loss: 0.3288 - val_accuracy: 0.8835\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2435 - accuracy: 0.9135 - val_loss: 0.3301 - val_accuracy: 0.8801\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2357 - accuracy: 0.9125 - val_loss: 0.3140 - val_accuracy: 0.8859\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2258 - accuracy: 0.9180 - val_loss: 0.3080 - val_accuracy: 0.8857\n",
            "Работает модель  128-64-32sgd  Итерация  0\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1836 - accuracy: 0.9335 - val_loss: 0.3144 - val_accuracy: 0.8953\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1677 - accuracy: 0.9377 - val_loss: 0.3168 - val_accuracy: 0.8940\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1640 - accuracy: 0.9400 - val_loss: 0.3191 - val_accuracy: 0.8945\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1569 - accuracy: 0.9425 - val_loss: 0.3218 - val_accuracy: 0.8950\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1570 - accuracy: 0.9430 - val_loss: 0.3196 - val_accuracy: 0.8948\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1601 - accuracy: 0.9413 - val_loss: 0.3199 - val_accuracy: 0.8955\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1580 - accuracy: 0.9421 - val_loss: 0.3222 - val_accuracy: 0.8947\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1584 - accuracy: 0.9422 - val_loss: 0.3225 - val_accuracy: 0.8966\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1548 - accuracy: 0.9433 - val_loss: 0.3258 - val_accuracy: 0.8934\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1555 - accuracy: 0.9427 - val_loss: 0.3246 - val_accuracy: 0.8963\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1528 - accuracy: 0.9457 - val_loss: 0.3259 - val_accuracy: 0.8951\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1564 - accuracy: 0.9433 - val_loss: 0.3246 - val_accuracy: 0.8948\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1551 - accuracy: 0.9437 - val_loss: 0.3276 - val_accuracy: 0.8948\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1560 - accuracy: 0.9433 - val_loss: 0.3285 - val_accuracy: 0.8919\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1533 - accuracy: 0.9437 - val_loss: 0.3292 - val_accuracy: 0.8949\n",
            "Работает модель  128-32sgd  Итерация  0\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2107 - accuracy: 0.9256 - val_loss: 0.2998 - val_accuracy: 0.8888\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2008 - accuracy: 0.9284 - val_loss: 0.2991 - val_accuracy: 0.8907\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2012 - accuracy: 0.9288 - val_loss: 0.2982 - val_accuracy: 0.8910\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1979 - accuracy: 0.9304 - val_loss: 0.2981 - val_accuracy: 0.8922\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1983 - accuracy: 0.9306 - val_loss: 0.2981 - val_accuracy: 0.8916\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1985 - accuracy: 0.9289 - val_loss: 0.2978 - val_accuracy: 0.8928\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1937 - accuracy: 0.9323 - val_loss: 0.2979 - val_accuracy: 0.8927\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1931 - accuracy: 0.9330 - val_loss: 0.2980 - val_accuracy: 0.8922\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1994 - accuracy: 0.9282 - val_loss: 0.2979 - val_accuracy: 0.8928\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1924 - accuracy: 0.9324 - val_loss: 0.2977 - val_accuracy: 0.8924\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1997 - accuracy: 0.9299 - val_loss: 0.2980 - val_accuracy: 0.8927\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1962 - accuracy: 0.9302 - val_loss: 0.2980 - val_accuracy: 0.8929\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1916 - accuracy: 0.9330 - val_loss: 0.2980 - val_accuracy: 0.8927\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1965 - accuracy: 0.9320 - val_loss: 0.2981 - val_accuracy: 0.8939\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1929 - accuracy: 0.9324 - val_loss: 0.2978 - val_accuracy: 0.8925\n",
            "Работает модель  128-64-32rms  Итерация  0\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2224 - accuracy: 0.9186 - val_loss: 0.3542 - val_accuracy: 0.8875\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2010 - accuracy: 0.9239 - val_loss: 0.3695 - val_accuracy: 0.8817\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1918 - accuracy: 0.9267 - val_loss: 0.3561 - val_accuracy: 0.8895\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1869 - accuracy: 0.9299 - val_loss: 0.3662 - val_accuracy: 0.8891\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1843 - accuracy: 0.9311 - val_loss: 0.3831 - val_accuracy: 0.8796\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1777 - accuracy: 0.9314 - val_loss: 0.4110 - val_accuracy: 0.8851\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1747 - accuracy: 0.9339 - val_loss: 0.4155 - val_accuracy: 0.8804\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1740 - accuracy: 0.9358 - val_loss: 0.3963 - val_accuracy: 0.8872\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1622 - accuracy: 0.9394 - val_loss: 0.4231 - val_accuracy: 0.8839\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1620 - accuracy: 0.9389 - val_loss: 0.4645 - val_accuracy: 0.8727\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1571 - accuracy: 0.9418 - val_loss: 0.4118 - val_accuracy: 0.8898\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1583 - accuracy: 0.9415 - val_loss: 0.4095 - val_accuracy: 0.8873\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1533 - accuracy: 0.9429 - val_loss: 0.4164 - val_accuracy: 0.8916\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1452 - accuracy: 0.9451 - val_loss: 0.4288 - val_accuracy: 0.8948\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1490 - accuracy: 0.9436 - val_loss: 0.4275 - val_accuracy: 0.8895\n",
            "Работает модель  128-32rms  Итерация  0\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 0.2257 - accuracy: 0.9174 - val_loss: 0.3104 - val_accuracy: 0.8873\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2120 - accuracy: 0.9221 - val_loss: 0.3058 - val_accuracy: 0.8883\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2113 - accuracy: 0.9229 - val_loss: 0.3042 - val_accuracy: 0.8912\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2069 - accuracy: 0.9231 - val_loss: 0.3340 - val_accuracy: 0.8808\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2018 - accuracy: 0.9276 - val_loss: 0.3163 - val_accuracy: 0.8874\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1958 - accuracy: 0.9298 - val_loss: 0.3173 - val_accuracy: 0.8883\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1911 - accuracy: 0.9314 - val_loss: 0.3153 - val_accuracy: 0.8902\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1903 - accuracy: 0.9296 - val_loss: 0.3423 - val_accuracy: 0.8790\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1856 - accuracy: 0.9329 - val_loss: 0.3288 - val_accuracy: 0.8844\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1774 - accuracy: 0.9359 - val_loss: 0.3309 - val_accuracy: 0.8852\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1782 - accuracy: 0.9343 - val_loss: 0.3130 - val_accuracy: 0.8928\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1722 - accuracy: 0.9375 - val_loss: 0.3374 - val_accuracy: 0.8863\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1665 - accuracy: 0.9390 - val_loss: 0.3276 - val_accuracy: 0.8895\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1704 - accuracy: 0.9387 - val_loss: 0.3245 - val_accuracy: 0.8920\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1660 - accuracy: 0.9396 - val_loss: 0.3271 - val_accuracy: 0.8917\n",
            "Работает модель  128-64-32a  Итерация  1\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 0.8992 - accuracy: 0.6926 - val_loss: 0.4616 - val_accuracy: 0.8284\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4135 - accuracy: 0.8518 - val_loss: 0.3900 - val_accuracy: 0.8581\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3614 - accuracy: 0.8688 - val_loss: 0.3748 - val_accuracy: 0.8625\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3314 - accuracy: 0.8786 - val_loss: 0.3780 - val_accuracy: 0.8618\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3145 - accuracy: 0.8873 - val_loss: 0.3497 - val_accuracy: 0.8753\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2989 - accuracy: 0.8898 - val_loss: 0.3343 - val_accuracy: 0.8792\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.8947 - val_loss: 0.3298 - val_accuracy: 0.8823\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2695 - accuracy: 0.8998 - val_loss: 0.3301 - val_accuracy: 0.8803\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2596 - accuracy: 0.9033 - val_loss: 0.3368 - val_accuracy: 0.8773\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2516 - accuracy: 0.9062 - val_loss: 0.3325 - val_accuracy: 0.8825\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2325 - accuracy: 0.9130 - val_loss: 0.3445 - val_accuracy: 0.8778\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2236 - accuracy: 0.9196 - val_loss: 0.3289 - val_accuracy: 0.8848\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2248 - accuracy: 0.9167 - val_loss: 0.3446 - val_accuracy: 0.8808\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2119 - accuracy: 0.9198 - val_loss: 0.3510 - val_accuracy: 0.8789\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2006 - accuracy: 0.9254 - val_loss: 0.3508 - val_accuracy: 0.8825\n",
            "Работает модель  128-64-32a  Итерация  1\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2473 - accuracy: 0.6601 - val_loss: 0.5375 - val_accuracy: 0.8313\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4993 - accuracy: 0.8418 - val_loss: 0.4370 - val_accuracy: 0.8494\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4117 - accuracy: 0.8612 - val_loss: 0.4112 - val_accuracy: 0.8517\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3664 - accuracy: 0.8719 - val_loss: 0.3701 - val_accuracy: 0.8702\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.8785 - val_loss: 0.3615 - val_accuracy: 0.8706\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.8841 - val_loss: 0.3568 - val_accuracy: 0.8695\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3045 - accuracy: 0.8921 - val_loss: 0.3347 - val_accuracy: 0.8781\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2864 - accuracy: 0.8993 - val_loss: 0.3350 - val_accuracy: 0.8786\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2802 - accuracy: 0.8992 - val_loss: 0.3225 - val_accuracy: 0.8846\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2757 - accuracy: 0.9005 - val_loss: 0.3167 - val_accuracy: 0.8856\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2581 - accuracy: 0.9080 - val_loss: 0.3266 - val_accuracy: 0.8806\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2501 - accuracy: 0.9114 - val_loss: 0.3195 - val_accuracy: 0.8846\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2454 - accuracy: 0.9125 - val_loss: 0.3179 - val_accuracy: 0.8875\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2389 - accuracy: 0.9130 - val_loss: 0.3133 - val_accuracy: 0.8863\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2334 - accuracy: 0.9158 - val_loss: 0.3105 - val_accuracy: 0.8913\n",
            "Работает модель  128-64-32sgd  Итерация  1\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1765 - accuracy: 0.9338 - val_loss: 0.3162 - val_accuracy: 0.8921\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1652 - accuracy: 0.9405 - val_loss: 0.3143 - val_accuracy: 0.8930\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1664 - accuracy: 0.9403 - val_loss: 0.3185 - val_accuracy: 0.8915\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1613 - accuracy: 0.9421 - val_loss: 0.3191 - val_accuracy: 0.8921\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1590 - accuracy: 0.9420 - val_loss: 0.3194 - val_accuracy: 0.8927\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1599 - accuracy: 0.9427 - val_loss: 0.3222 - val_accuracy: 0.8897\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1574 - accuracy: 0.9434 - val_loss: 0.3242 - val_accuracy: 0.8898\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1551 - accuracy: 0.9448 - val_loss: 0.3222 - val_accuracy: 0.8925\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1521 - accuracy: 0.9450 - val_loss: 0.3238 - val_accuracy: 0.8908\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1573 - accuracy: 0.9420 - val_loss: 0.3230 - val_accuracy: 0.8924\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1524 - accuracy: 0.9457 - val_loss: 0.3255 - val_accuracy: 0.8909\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1505 - accuracy: 0.9454 - val_loss: 0.3259 - val_accuracy: 0.8923\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1488 - accuracy: 0.9456 - val_loss: 0.3283 - val_accuracy: 0.8922\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1536 - accuracy: 0.9450 - val_loss: 0.3301 - val_accuracy: 0.8911\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1468 - accuracy: 0.9473 - val_loss: 0.3298 - val_accuracy: 0.8911\n",
            "Работает модель  128-32sgd  Итерация  1\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2192 - accuracy: 0.9206 - val_loss: 0.3019 - val_accuracy: 0.8917\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2076 - accuracy: 0.9279 - val_loss: 0.3009 - val_accuracy: 0.8923\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2013 - accuracy: 0.9287 - val_loss: 0.2999 - val_accuracy: 0.8923\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2058 - accuracy: 0.9283 - val_loss: 0.3002 - val_accuracy: 0.8915\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2022 - accuracy: 0.9287 - val_loss: 0.2997 - val_accuracy: 0.8923\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2013 - accuracy: 0.9289 - val_loss: 0.3000 - val_accuracy: 0.8923\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2007 - accuracy: 0.9288 - val_loss: 0.2995 - val_accuracy: 0.8928\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2009 - accuracy: 0.9294 - val_loss: 0.3000 - val_accuracy: 0.8927\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2035 - accuracy: 0.9277 - val_loss: 0.2994 - val_accuracy: 0.8936\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2006 - accuracy: 0.9290 - val_loss: 0.2996 - val_accuracy: 0.8932\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2037 - accuracy: 0.9283 - val_loss: 0.2994 - val_accuracy: 0.8936\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1974 - accuracy: 0.9308 - val_loss: 0.2997 - val_accuracy: 0.8929\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1961 - accuracy: 0.9302 - val_loss: 0.2997 - val_accuracy: 0.8936\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1989 - accuracy: 0.9308 - val_loss: 0.2999 - val_accuracy: 0.8927\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2004 - accuracy: 0.9298 - val_loss: 0.3002 - val_accuracy: 0.8921\n",
            "Работает модель  128-64-32rms  Итерация  1\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2155 - accuracy: 0.9200 - val_loss: 0.3507 - val_accuracy: 0.8870\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1957 - accuracy: 0.9255 - val_loss: 0.3692 - val_accuracy: 0.8810\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1972 - accuracy: 0.9265 - val_loss: 0.4242 - val_accuracy: 0.8723\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1874 - accuracy: 0.9291 - val_loss: 0.3816 - val_accuracy: 0.8852\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1842 - accuracy: 0.9307 - val_loss: 0.3872 - val_accuracy: 0.8809\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1794 - accuracy: 0.9326 - val_loss: 0.3740 - val_accuracy: 0.8872\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1709 - accuracy: 0.9350 - val_loss: 0.3599 - val_accuracy: 0.8903\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1655 - accuracy: 0.9373 - val_loss: 0.4034 - val_accuracy: 0.8845\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1678 - accuracy: 0.9380 - val_loss: 0.4030 - val_accuracy: 0.8832\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9400 - val_loss: 0.4107 - val_accuracy: 0.8834\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1596 - accuracy: 0.9410 - val_loss: 0.4504 - val_accuracy: 0.8848\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1538 - accuracy: 0.9414 - val_loss: 0.4419 - val_accuracy: 0.8850\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1521 - accuracy: 0.9429 - val_loss: 0.4456 - val_accuracy: 0.8838\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1493 - accuracy: 0.9438 - val_loss: 0.4309 - val_accuracy: 0.8841\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1420 - accuracy: 0.9455 - val_loss: 0.4198 - val_accuracy: 0.8823\n",
            "Работает модель  128-32rms  Итерация  1\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 0.2265 - accuracy: 0.9169 - val_loss: 0.3163 - val_accuracy: 0.8891\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2176 - accuracy: 0.9201 - val_loss: 0.3235 - val_accuracy: 0.8843\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2179 - accuracy: 0.9212 - val_loss: 0.3136 - val_accuracy: 0.8904\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2108 - accuracy: 0.9240 - val_loss: 0.3190 - val_accuracy: 0.8869\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2092 - accuracy: 0.9233 - val_loss: 0.3133 - val_accuracy: 0.8920\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2068 - accuracy: 0.9259 - val_loss: 0.3149 - val_accuracy: 0.8912\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1960 - accuracy: 0.9285 - val_loss: 0.3218 - val_accuracy: 0.8889\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1917 - accuracy: 0.9312 - val_loss: 0.3256 - val_accuracy: 0.8910\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1931 - accuracy: 0.9321 - val_loss: 0.3171 - val_accuracy: 0.8895\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1878 - accuracy: 0.9317 - val_loss: 0.3261 - val_accuracy: 0.8912\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1797 - accuracy: 0.9351 - val_loss: 0.3220 - val_accuracy: 0.8913\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1760 - accuracy: 0.9367 - val_loss: 0.3208 - val_accuracy: 0.8921\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1747 - accuracy: 0.9366 - val_loss: 0.3591 - val_accuracy: 0.8739\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1707 - accuracy: 0.9383 - val_loss: 0.3301 - val_accuracy: 0.8884\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1695 - accuracy: 0.9370 - val_loss: 0.3475 - val_accuracy: 0.8852\n",
            "Работает модель  128-64-32a  Итерация  2\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 0.9008 - accuracy: 0.6898 - val_loss: 0.4541 - val_accuracy: 0.8360\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4195 - accuracy: 0.8476 - val_loss: 0.3951 - val_accuracy: 0.8574\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3687 - accuracy: 0.8689 - val_loss: 0.3678 - val_accuracy: 0.8697\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3383 - accuracy: 0.8772 - val_loss: 0.3865 - val_accuracy: 0.8636\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3181 - accuracy: 0.8852 - val_loss: 0.3521 - val_accuracy: 0.8755\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3069 - accuracy: 0.8891 - val_loss: 0.3501 - val_accuracy: 0.8747\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2850 - accuracy: 0.8951 - val_loss: 0.3433 - val_accuracy: 0.8813\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2657 - accuracy: 0.9006 - val_loss: 0.3320 - val_accuracy: 0.8844\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2506 - accuracy: 0.9090 - val_loss: 0.3476 - val_accuracy: 0.8769\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2465 - accuracy: 0.9082 - val_loss: 0.3463 - val_accuracy: 0.8827\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2458 - accuracy: 0.9076 - val_loss: 0.3327 - val_accuracy: 0.8856\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2301 - accuracy: 0.9154 - val_loss: 0.3349 - val_accuracy: 0.8855\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2245 - accuracy: 0.9168 - val_loss: 0.3400 - val_accuracy: 0.8838\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2195 - accuracy: 0.9191 - val_loss: 0.3312 - val_accuracy: 0.8873\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2079 - accuracy: 0.9234 - val_loss: 0.3359 - val_accuracy: 0.8879\n",
            "Работает модель  128-64-32a  Итерация  2\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 1.1482 - accuracy: 0.6630 - val_loss: 0.5220 - val_accuracy: 0.8338\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.8395 - val_loss: 0.4270 - val_accuracy: 0.8522\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3991 - accuracy: 0.8627 - val_loss: 0.3947 - val_accuracy: 0.8602\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3614 - accuracy: 0.8755 - val_loss: 0.3637 - val_accuracy: 0.8707\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3335 - accuracy: 0.8841 - val_loss: 0.3711 - val_accuracy: 0.8665\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.8826 - val_loss: 0.3424 - val_accuracy: 0.8779\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3026 - accuracy: 0.8903 - val_loss: 0.3450 - val_accuracy: 0.8744\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2906 - accuracy: 0.8946 - val_loss: 0.3378 - val_accuracy: 0.8784\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2785 - accuracy: 0.8982 - val_loss: 0.3232 - val_accuracy: 0.8836\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2647 - accuracy: 0.9035 - val_loss: 0.3209 - val_accuracy: 0.8847\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2594 - accuracy: 0.9071 - val_loss: 0.3253 - val_accuracy: 0.8791\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2498 - accuracy: 0.9091 - val_loss: 0.3120 - val_accuracy: 0.8890\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2462 - accuracy: 0.9092 - val_loss: 0.3180 - val_accuracy: 0.8843\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2419 - accuracy: 0.9115 - val_loss: 0.3088 - val_accuracy: 0.8882\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2237 - accuracy: 0.9191 - val_loss: 0.3143 - val_accuracy: 0.8861\n",
            "Работает модель  128-64-32sgd  Итерация  2\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1809 - accuracy: 0.9329 - val_loss: 0.3129 - val_accuracy: 0.8945\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1684 - accuracy: 0.9386 - val_loss: 0.3151 - val_accuracy: 0.8957\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1626 - accuracy: 0.9403 - val_loss: 0.3161 - val_accuracy: 0.8944\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1665 - accuracy: 0.9390 - val_loss: 0.3186 - val_accuracy: 0.8953\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1630 - accuracy: 0.9412 - val_loss: 0.3222 - val_accuracy: 0.8938\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1605 - accuracy: 0.9411 - val_loss: 0.3214 - val_accuracy: 0.8947\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1597 - accuracy: 0.9415 - val_loss: 0.3213 - val_accuracy: 0.8951\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1573 - accuracy: 0.9430 - val_loss: 0.3229 - val_accuracy: 0.8957\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1552 - accuracy: 0.9434 - val_loss: 0.3247 - val_accuracy: 0.8938\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1571 - accuracy: 0.9432 - val_loss: 0.3266 - val_accuracy: 0.8940\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1566 - accuracy: 0.9424 - val_loss: 0.3268 - val_accuracy: 0.8953\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1598 - accuracy: 0.9398 - val_loss: 0.3257 - val_accuracy: 0.8949\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1553 - accuracy: 0.9434 - val_loss: 0.3308 - val_accuracy: 0.8945\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1542 - accuracy: 0.9442 - val_loss: 0.3290 - val_accuracy: 0.8950\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1525 - accuracy: 0.9437 - val_loss: 0.3292 - val_accuracy: 0.8942\n",
            "Работает модель  128-32sgd  Итерация  2\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2138 - accuracy: 0.9233 - val_loss: 0.2999 - val_accuracy: 0.8915\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2086 - accuracy: 0.9248 - val_loss: 0.2990 - val_accuracy: 0.8920\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2034 - accuracy: 0.9271 - val_loss: 0.2988 - val_accuracy: 0.8921\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2013 - accuracy: 0.9284 - val_loss: 0.2985 - val_accuracy: 0.8923\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2003 - accuracy: 0.9282 - val_loss: 0.2981 - val_accuracy: 0.8913\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2050 - accuracy: 0.9273 - val_loss: 0.2981 - val_accuracy: 0.8909\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1980 - accuracy: 0.9299 - val_loss: 0.2981 - val_accuracy: 0.8919\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2034 - accuracy: 0.9265 - val_loss: 0.2983 - val_accuracy: 0.8931\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1984 - accuracy: 0.9301 - val_loss: 0.2979 - val_accuracy: 0.8930\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1976 - accuracy: 0.9291 - val_loss: 0.2981 - val_accuracy: 0.8926\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1994 - accuracy: 0.9291 - val_loss: 0.2981 - val_accuracy: 0.8926\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1988 - accuracy: 0.9292 - val_loss: 0.2980 - val_accuracy: 0.8926\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1932 - accuracy: 0.9310 - val_loss: 0.2982 - val_accuracy: 0.8923\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2002 - accuracy: 0.9280 - val_loss: 0.2982 - val_accuracy: 0.8932\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1982 - accuracy: 0.9302 - val_loss: 0.2984 - val_accuracy: 0.8932\n",
            "Работает модель  128-64-32rms  Итерация  2\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2145 - accuracy: 0.9194 - val_loss: 0.4106 - val_accuracy: 0.8738\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2012 - accuracy: 0.9242 - val_loss: 0.3622 - val_accuracy: 0.8887\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1987 - accuracy: 0.9267 - val_loss: 0.4251 - val_accuracy: 0.8753\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1924 - accuracy: 0.9271 - val_loss: 0.3709 - val_accuracy: 0.8837\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1881 - accuracy: 0.9293 - val_loss: 0.3978 - val_accuracy: 0.8823\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1782 - accuracy: 0.9329 - val_loss: 0.4386 - val_accuracy: 0.8691\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1761 - accuracy: 0.9345 - val_loss: 0.3642 - val_accuracy: 0.8915\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1692 - accuracy: 0.9366 - val_loss: 0.4120 - val_accuracy: 0.8849\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1718 - accuracy: 0.9356 - val_loss: 0.4251 - val_accuracy: 0.8773\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1661 - accuracy: 0.9361 - val_loss: 0.4136 - val_accuracy: 0.8816\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1619 - accuracy: 0.9383 - val_loss: 0.4136 - val_accuracy: 0.8875\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1608 - accuracy: 0.9386 - val_loss: 0.4332 - val_accuracy: 0.8825\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1546 - accuracy: 0.9411 - val_loss: 0.4131 - val_accuracy: 0.8887\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1542 - accuracy: 0.9413 - val_loss: 0.4562 - val_accuracy: 0.8850\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1497 - accuracy: 0.9442 - val_loss: 0.4560 - val_accuracy: 0.8860\n",
            "Работает модель  128-32rms  Итерация  2\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2285 - accuracy: 0.9172 - val_loss: 0.3269 - val_accuracy: 0.8817\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2207 - accuracy: 0.9200 - val_loss: 0.3252 - val_accuracy: 0.8848\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2135 - accuracy: 0.9225 - val_loss: 0.3243 - val_accuracy: 0.8852\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2064 - accuracy: 0.9252 - val_loss: 0.3283 - val_accuracy: 0.8838\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2099 - accuracy: 0.9232 - val_loss: 0.3188 - val_accuracy: 0.8883\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2009 - accuracy: 0.9265 - val_loss: 0.3119 - val_accuracy: 0.8907\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1995 - accuracy: 0.9265 - val_loss: 0.3100 - val_accuracy: 0.8888\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1948 - accuracy: 0.9285 - val_loss: 0.3193 - val_accuracy: 0.8898\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1879 - accuracy: 0.9328 - val_loss: 0.3189 - val_accuracy: 0.8900\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1852 - accuracy: 0.9329 - val_loss: 0.3191 - val_accuracy: 0.8920\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1800 - accuracy: 0.9346 - val_loss: 0.3270 - val_accuracy: 0.8887\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1773 - accuracy: 0.9366 - val_loss: 0.3384 - val_accuracy: 0.8852\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1745 - accuracy: 0.9379 - val_loss: 0.3264 - val_accuracy: 0.8904\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1706 - accuracy: 0.9382 - val_loss: 0.3177 - val_accuracy: 0.8935\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1652 - accuracy: 0.9393 - val_loss: 0.3405 - val_accuracy: 0.8866\n",
            "Работает модель  128-64-32a  Итерация  3\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 1.1219 - accuracy: 0.6496 - val_loss: 0.4756 - val_accuracy: 0.8291\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4367 - accuracy: 0.8459 - val_loss: 0.4138 - val_accuracy: 0.8560\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3786 - accuracy: 0.8615 - val_loss: 0.3755 - val_accuracy: 0.8665\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.8771 - val_loss: 0.3789 - val_accuracy: 0.8633\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3172 - accuracy: 0.8808 - val_loss: 0.3472 - val_accuracy: 0.8752\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3057 - accuracy: 0.8875 - val_loss: 0.3549 - val_accuracy: 0.8734\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2785 - accuracy: 0.8980 - val_loss: 0.3387 - val_accuracy: 0.8798\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2692 - accuracy: 0.9004 - val_loss: 0.3536 - val_accuracy: 0.8747\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2680 - accuracy: 0.8999 - val_loss: 0.3452 - val_accuracy: 0.8774\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2504 - accuracy: 0.9059 - val_loss: 0.3256 - val_accuracy: 0.8844\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2355 - accuracy: 0.9127 - val_loss: 0.3412 - val_accuracy: 0.8831\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2379 - accuracy: 0.9112 - val_loss: 0.3298 - val_accuracy: 0.8865\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2212 - accuracy: 0.9173 - val_loss: 0.3384 - val_accuracy: 0.8823\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2143 - accuracy: 0.9198 - val_loss: 0.3399 - val_accuracy: 0.8846\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2087 - accuracy: 0.9218 - val_loss: 0.3403 - val_accuracy: 0.8838\n",
            "Работает модель  128-64-32a  Итерация  3\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 1.1898 - accuracy: 0.6605 - val_loss: 0.5169 - val_accuracy: 0.8321\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4816 - accuracy: 0.8408 - val_loss: 0.4393 - val_accuracy: 0.8460\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3976 - accuracy: 0.8612 - val_loss: 0.4054 - val_accuracy: 0.8562\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3675 - accuracy: 0.8703 - val_loss: 0.3754 - val_accuracy: 0.8642\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8795 - val_loss: 0.3651 - val_accuracy: 0.8711\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3188 - accuracy: 0.8864 - val_loss: 0.3481 - val_accuracy: 0.8728\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3024 - accuracy: 0.8904 - val_loss: 0.3522 - val_accuracy: 0.8743\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2918 - accuracy: 0.8939 - val_loss: 0.3284 - val_accuracy: 0.8811\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.8993 - val_loss: 0.3204 - val_accuracy: 0.8817\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2747 - accuracy: 0.9017 - val_loss: 0.3171 - val_accuracy: 0.8878\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2602 - accuracy: 0.9032 - val_loss: 0.3450 - val_accuracy: 0.8738\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2596 - accuracy: 0.9074 - val_loss: 0.3193 - val_accuracy: 0.8867\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2470 - accuracy: 0.9105 - val_loss: 0.3104 - val_accuracy: 0.8894\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2382 - accuracy: 0.9139 - val_loss: 0.3145 - val_accuracy: 0.8867\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2267 - accuracy: 0.9170 - val_loss: 0.3225 - val_accuracy: 0.8840\n",
            "Работает модель  128-64-32sgd  Итерация  3\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 0.1815 - accuracy: 0.9315 - val_loss: 0.3187 - val_accuracy: 0.8917\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1720 - accuracy: 0.9387 - val_loss: 0.3203 - val_accuracy: 0.8935\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1632 - accuracy: 0.9403 - val_loss: 0.3177 - val_accuracy: 0.8931\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1641 - accuracy: 0.9405 - val_loss: 0.3191 - val_accuracy: 0.8936\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1579 - accuracy: 0.9426 - val_loss: 0.3203 - val_accuracy: 0.8922\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1592 - accuracy: 0.9416 - val_loss: 0.3197 - val_accuracy: 0.8931\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1643 - accuracy: 0.9391 - val_loss: 0.3202 - val_accuracy: 0.8935\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1597 - accuracy: 0.9429 - val_loss: 0.3223 - val_accuracy: 0.8933\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1602 - accuracy: 0.9397 - val_loss: 0.3240 - val_accuracy: 0.8917\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1563 - accuracy: 0.9425 - val_loss: 0.3210 - val_accuracy: 0.8934\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1554 - accuracy: 0.9433 - val_loss: 0.3241 - val_accuracy: 0.8940\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1524 - accuracy: 0.9450 - val_loss: 0.3251 - val_accuracy: 0.8937\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1542 - accuracy: 0.9431 - val_loss: 0.3274 - val_accuracy: 0.8941\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1514 - accuracy: 0.9440 - val_loss: 0.3257 - val_accuracy: 0.8934\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1506 - accuracy: 0.9437 - val_loss: 0.3272 - val_accuracy: 0.8924\n",
            "Работает модель  128-32sgd  Итерация  3\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2117 - accuracy: 0.9240 - val_loss: 0.3022 - val_accuracy: 0.8913\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2046 - accuracy: 0.9260 - val_loss: 0.3018 - val_accuracy: 0.8923\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2030 - accuracy: 0.9276 - val_loss: 0.3012 - val_accuracy: 0.8926\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1987 - accuracy: 0.9290 - val_loss: 0.3012 - val_accuracy: 0.8932\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2062 - accuracy: 0.9269 - val_loss: 0.3010 - val_accuracy: 0.8937\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2004 - accuracy: 0.9286 - val_loss: 0.3009 - val_accuracy: 0.8937\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2009 - accuracy: 0.9275 - val_loss: 0.3008 - val_accuracy: 0.8929\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2005 - accuracy: 0.9292 - val_loss: 0.3011 - val_accuracy: 0.8929\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2032 - accuracy: 0.9273 - val_loss: 0.3011 - val_accuracy: 0.8933\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1937 - accuracy: 0.9309 - val_loss: 0.3010 - val_accuracy: 0.8933\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1992 - accuracy: 0.9294 - val_loss: 0.3014 - val_accuracy: 0.8931\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2002 - accuracy: 0.9297 - val_loss: 0.3010 - val_accuracy: 0.8933\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2005 - accuracy: 0.9290 - val_loss: 0.3014 - val_accuracy: 0.8932\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2002 - accuracy: 0.9279 - val_loss: 0.3013 - val_accuracy: 0.8925\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2001 - accuracy: 0.9275 - val_loss: 0.3013 - val_accuracy: 0.8923\n",
            "Работает модель  128-64-32rms  Итерация  3\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2219 - accuracy: 0.9192 - val_loss: 0.3797 - val_accuracy: 0.8793\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1994 - accuracy: 0.9252 - val_loss: 0.3706 - val_accuracy: 0.8825\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1975 - accuracy: 0.9264 - val_loss: 0.4036 - val_accuracy: 0.8717\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1874 - accuracy: 0.9287 - val_loss: 0.3612 - val_accuracy: 0.8863\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1818 - accuracy: 0.9313 - val_loss: 0.4137 - val_accuracy: 0.8775\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1785 - accuracy: 0.9320 - val_loss: 0.3985 - val_accuracy: 0.8888\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1733 - accuracy: 0.9334 - val_loss: 0.4076 - val_accuracy: 0.8825\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1686 - accuracy: 0.9364 - val_loss: 0.3942 - val_accuracy: 0.8907\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1646 - accuracy: 0.9377 - val_loss: 0.3865 - val_accuracy: 0.8841\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1620 - accuracy: 0.9398 - val_loss: 0.4241 - val_accuracy: 0.8858\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1556 - accuracy: 0.9422 - val_loss: 0.4421 - val_accuracy: 0.8807\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1551 - accuracy: 0.9419 - val_loss: 0.4366 - val_accuracy: 0.8829\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1538 - accuracy: 0.9431 - val_loss: 0.4369 - val_accuracy: 0.8862\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1498 - accuracy: 0.9468 - val_loss: 0.4227 - val_accuracy: 0.8867\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1406 - accuracy: 0.9470 - val_loss: 0.4978 - val_accuracy: 0.8778\n",
            "Работает модель  128-32rms  Итерация  3\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2334 - accuracy: 0.9148 - val_loss: 0.3591 - val_accuracy: 0.8748\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2213 - accuracy: 0.9194 - val_loss: 0.3192 - val_accuracy: 0.8883\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2183 - accuracy: 0.9190 - val_loss: 0.3162 - val_accuracy: 0.8911\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2133 - accuracy: 0.9197 - val_loss: 0.3343 - val_accuracy: 0.8831\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2072 - accuracy: 0.9225 - val_loss: 0.3163 - val_accuracy: 0.8893\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2037 - accuracy: 0.9273 - val_loss: 0.3352 - val_accuracy: 0.8870\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1965 - accuracy: 0.9283 - val_loss: 0.3260 - val_accuracy: 0.8878\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1984 - accuracy: 0.9261 - val_loss: 0.3301 - val_accuracy: 0.8851\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1839 - accuracy: 0.9324 - val_loss: 0.3540 - val_accuracy: 0.8792\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1885 - accuracy: 0.9315 - val_loss: 0.3453 - val_accuracy: 0.8838\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1813 - accuracy: 0.9340 - val_loss: 0.3242 - val_accuracy: 0.8923\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1729 - accuracy: 0.9361 - val_loss: 0.3258 - val_accuracy: 0.8909\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1692 - accuracy: 0.9381 - val_loss: 0.3247 - val_accuracy: 0.8905\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1708 - accuracy: 0.9383 - val_loss: 0.3410 - val_accuracy: 0.8854\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1671 - accuracy: 0.9385 - val_loss: 0.3290 - val_accuracy: 0.8892\n",
            "Работает модель  128-64-32a  Итерация  4\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9400 - accuracy: 0.6840 - val_loss: 0.4669 - val_accuracy: 0.8369\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4192 - accuracy: 0.8524 - val_loss: 0.4131 - val_accuracy: 0.8518\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3640 - accuracy: 0.8681 - val_loss: 0.3734 - val_accuracy: 0.8675\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3411 - accuracy: 0.8754 - val_loss: 0.3807 - val_accuracy: 0.8641\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3227 - accuracy: 0.8838 - val_loss: 0.3499 - val_accuracy: 0.8717\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2987 - accuracy: 0.8888 - val_loss: 0.3632 - val_accuracy: 0.8664\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2794 - accuracy: 0.8976 - val_loss: 0.3527 - val_accuracy: 0.8734\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2721 - accuracy: 0.9005 - val_loss: 0.3561 - val_accuracy: 0.8748\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2573 - accuracy: 0.9058 - val_loss: 0.3481 - val_accuracy: 0.8725\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2508 - accuracy: 0.9080 - val_loss: 0.3425 - val_accuracy: 0.8783\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2409 - accuracy: 0.9106 - val_loss: 0.3264 - val_accuracy: 0.8843\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2332 - accuracy: 0.9149 - val_loss: 0.3384 - val_accuracy: 0.8849\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2296 - accuracy: 0.9136 - val_loss: 0.3674 - val_accuracy: 0.8758\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2197 - accuracy: 0.9168 - val_loss: 0.3355 - val_accuracy: 0.8848\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2106 - accuracy: 0.9220 - val_loss: 0.3456 - val_accuracy: 0.8854\n",
            "Работает модель  128-64-32a  Итерация  4\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 1.2205 - accuracy: 0.6633 - val_loss: 0.5356 - val_accuracy: 0.8282\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4897 - accuracy: 0.8382 - val_loss: 0.4252 - val_accuracy: 0.8528\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3993 - accuracy: 0.8625 - val_loss: 0.3846 - val_accuracy: 0.8658\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3569 - accuracy: 0.8749 - val_loss: 0.3779 - val_accuracy: 0.8621\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.8819 - val_loss: 0.3436 - val_accuracy: 0.8752\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3139 - accuracy: 0.8871 - val_loss: 0.3435 - val_accuracy: 0.8785\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3006 - accuracy: 0.8926 - val_loss: 0.3334 - val_accuracy: 0.8771\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2870 - accuracy: 0.8978 - val_loss: 0.3210 - val_accuracy: 0.8838\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2757 - accuracy: 0.9001 - val_loss: 0.3199 - val_accuracy: 0.8828\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2593 - accuracy: 0.9092 - val_loss: 0.3155 - val_accuracy: 0.8848\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2544 - accuracy: 0.9066 - val_loss: 0.3097 - val_accuracy: 0.8862\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2550 - accuracy: 0.9067 - val_loss: 0.3143 - val_accuracy: 0.8867\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2412 - accuracy: 0.9136 - val_loss: 0.3110 - val_accuracy: 0.8870\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2292 - accuracy: 0.9171 - val_loss: 0.3137 - val_accuracy: 0.8886\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2229 - accuracy: 0.9189 - val_loss: 0.3080 - val_accuracy: 0.8872\n",
            "Работает модель  128-64-32sgd  Итерация  4\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1758 - accuracy: 0.9349 - val_loss: 0.3257 - val_accuracy: 0.8932\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1624 - accuracy: 0.9419 - val_loss: 0.3247 - val_accuracy: 0.8913\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1682 - accuracy: 0.9393 - val_loss: 0.3288 - val_accuracy: 0.8917\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1650 - accuracy: 0.9411 - val_loss: 0.3271 - val_accuracy: 0.8925\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1640 - accuracy: 0.9404 - val_loss: 0.3280 - val_accuracy: 0.8934\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1610 - accuracy: 0.9406 - val_loss: 0.3271 - val_accuracy: 0.8938\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1587 - accuracy: 0.9429 - val_loss: 0.3315 - val_accuracy: 0.8921\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1626 - accuracy: 0.9419 - val_loss: 0.3314 - val_accuracy: 0.8942\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1560 - accuracy: 0.9441 - val_loss: 0.3305 - val_accuracy: 0.8946\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1570 - accuracy: 0.9432 - val_loss: 0.3323 - val_accuracy: 0.8919\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1572 - accuracy: 0.9430 - val_loss: 0.3379 - val_accuracy: 0.8909\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1601 - accuracy: 0.9425 - val_loss: 0.3371 - val_accuracy: 0.8905\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1535 - accuracy: 0.9446 - val_loss: 0.3376 - val_accuracy: 0.8914\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1593 - accuracy: 0.9423 - val_loss: 0.3381 - val_accuracy: 0.8917\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1503 - accuracy: 0.9458 - val_loss: 0.3354 - val_accuracy: 0.8921\n",
            "Работает модель  128-32sgd  Итерация  4\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 0.2037 - accuracy: 0.9282 - val_loss: 0.3005 - val_accuracy: 0.8904\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2020 - accuracy: 0.9283 - val_loss: 0.3003 - val_accuracy: 0.8913\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1944 - accuracy: 0.9319 - val_loss: 0.2999 - val_accuracy: 0.8905\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1959 - accuracy: 0.9313 - val_loss: 0.2997 - val_accuracy: 0.8912\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1970 - accuracy: 0.9308 - val_loss: 0.2994 - val_accuracy: 0.8914\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1923 - accuracy: 0.9315 - val_loss: 0.2994 - val_accuracy: 0.8917\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1938 - accuracy: 0.9307 - val_loss: 0.2994 - val_accuracy: 0.8917\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1950 - accuracy: 0.9307 - val_loss: 0.2995 - val_accuracy: 0.8912\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1954 - accuracy: 0.9310 - val_loss: 0.2991 - val_accuracy: 0.8917\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1962 - accuracy: 0.9289 - val_loss: 0.2995 - val_accuracy: 0.8927\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1975 - accuracy: 0.9296 - val_loss: 0.2994 - val_accuracy: 0.8917\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1888 - accuracy: 0.9335 - val_loss: 0.2998 - val_accuracy: 0.8916\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1969 - accuracy: 0.9292 - val_loss: 0.2995 - val_accuracy: 0.8919\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1942 - accuracy: 0.9313 - val_loss: 0.2993 - val_accuracy: 0.8914\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1924 - accuracy: 0.9316 - val_loss: 0.2993 - val_accuracy: 0.8921\n",
            "Работает модель  128-64-32rms  Итерация  4\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2201 - accuracy: 0.9216 - val_loss: 0.4235 - val_accuracy: 0.8689\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9225 - val_loss: 0.4307 - val_accuracy: 0.8687\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1919 - accuracy: 0.9280 - val_loss: 0.4209 - val_accuracy: 0.8708\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1881 - accuracy: 0.9309 - val_loss: 0.3994 - val_accuracy: 0.8742\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1810 - accuracy: 0.9315 - val_loss: 0.4224 - val_accuracy: 0.8755\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9308 - val_loss: 0.3960 - val_accuracy: 0.8857\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1769 - accuracy: 0.9351 - val_loss: 0.4287 - val_accuracy: 0.8788\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1724 - accuracy: 0.9352 - val_loss: 0.4091 - val_accuracy: 0.8788\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1666 - accuracy: 0.9389 - val_loss: 0.3958 - val_accuracy: 0.8863\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1615 - accuracy: 0.9379 - val_loss: 0.4161 - val_accuracy: 0.8809\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1589 - accuracy: 0.9412 - val_loss: 0.4368 - val_accuracy: 0.8856\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1576 - accuracy: 0.9414 - val_loss: 0.4453 - val_accuracy: 0.8835\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9434 - val_loss: 0.4267 - val_accuracy: 0.8819\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1463 - accuracy: 0.9456 - val_loss: 0.4277 - val_accuracy: 0.8869\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1467 - accuracy: 0.9446 - val_loss: 0.4408 - val_accuracy: 0.8823\n",
            "Работает модель  128-32rms  Итерация  4\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2236 - accuracy: 0.9200 - val_loss: 0.3274 - val_accuracy: 0.8846\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2146 - accuracy: 0.9217 - val_loss: 0.3098 - val_accuracy: 0.8885\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2091 - accuracy: 0.9234 - val_loss: 0.3345 - val_accuracy: 0.8808\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2046 - accuracy: 0.9240 - val_loss: 0.3094 - val_accuracy: 0.8924\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2047 - accuracy: 0.9246 - val_loss: 0.3156 - val_accuracy: 0.8886\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1949 - accuracy: 0.9275 - val_loss: 0.3169 - val_accuracy: 0.8896\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1937 - accuracy: 0.9288 - val_loss: 0.3288 - val_accuracy: 0.8868\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1913 - accuracy: 0.9284 - val_loss: 0.3253 - val_accuracy: 0.8886\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1852 - accuracy: 0.9315 - val_loss: 0.3177 - val_accuracy: 0.8904\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1752 - accuracy: 0.9346 - val_loss: 0.3184 - val_accuracy: 0.8916\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1797 - accuracy: 0.9356 - val_loss: 0.3211 - val_accuracy: 0.8915\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1689 - accuracy: 0.9375 - val_loss: 0.3412 - val_accuracy: 0.8852\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1700 - accuracy: 0.9377 - val_loss: 0.3301 - val_accuracy: 0.8922\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1670 - accuracy: 0.9398 - val_loss: 0.3312 - val_accuracy: 0.8929\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1612 - accuracy: 0.9413 - val_loss: 0.3348 - val_accuracy: 0.8908\n",
            "Работает модель  128-64-32a  Итерация  5\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8830 - accuracy: 0.7090 - val_loss: 0.4363 - val_accuracy: 0.8452\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4101 - accuracy: 0.8551 - val_loss: 0.4039 - val_accuracy: 0.8545\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3628 - accuracy: 0.8676 - val_loss: 0.3888 - val_accuracy: 0.8617\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8807 - val_loss: 0.3510 - val_accuracy: 0.8748\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3080 - accuracy: 0.8884 - val_loss: 0.3498 - val_accuracy: 0.8755\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2939 - accuracy: 0.8929 - val_loss: 0.3380 - val_accuracy: 0.8767\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.8985 - val_loss: 0.3293 - val_accuracy: 0.8804\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.8987 - val_loss: 0.3159 - val_accuracy: 0.8856\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2527 - accuracy: 0.9077 - val_loss: 0.3342 - val_accuracy: 0.8793\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2438 - accuracy: 0.9100 - val_loss: 0.3330 - val_accuracy: 0.8800\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2326 - accuracy: 0.9136 - val_loss: 0.3429 - val_accuracy: 0.8816\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2325 - accuracy: 0.9136 - val_loss: 0.3460 - val_accuracy: 0.8777\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2178 - accuracy: 0.9204 - val_loss: 0.3504 - val_accuracy: 0.8827\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2065 - accuracy: 0.9229 - val_loss: 0.3423 - val_accuracy: 0.8847\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2060 - accuracy: 0.9242 - val_loss: 0.3445 - val_accuracy: 0.8828\n",
            "Работает модель  128-64-32a  Итерация  5\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2452 - accuracy: 0.6443 - val_loss: 0.5334 - val_accuracy: 0.8298\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4990 - accuracy: 0.8387 - val_loss: 0.4336 - val_accuracy: 0.8478\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4095 - accuracy: 0.8613 - val_loss: 0.3871 - val_accuracy: 0.8623\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3706 - accuracy: 0.8718 - val_loss: 0.3715 - val_accuracy: 0.8663\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3329 - accuracy: 0.8840 - val_loss: 0.3477 - val_accuracy: 0.8751\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3184 - accuracy: 0.8874 - val_loss: 0.3492 - val_accuracy: 0.8742\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2997 - accuracy: 0.8935 - val_loss: 0.3365 - val_accuracy: 0.8788\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2942 - accuracy: 0.8947 - val_loss: 0.3202 - val_accuracy: 0.8867\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.9024 - val_loss: 0.3277 - val_accuracy: 0.8783\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2712 - accuracy: 0.9028 - val_loss: 0.3267 - val_accuracy: 0.8819\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2570 - accuracy: 0.9077 - val_loss: 0.3173 - val_accuracy: 0.8849\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2515 - accuracy: 0.9109 - val_loss: 0.3124 - val_accuracy: 0.8881\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2408 - accuracy: 0.9135 - val_loss: 0.3146 - val_accuracy: 0.8861\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2329 - accuracy: 0.9148 - val_loss: 0.3107 - val_accuracy: 0.8879\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2283 - accuracy: 0.9173 - val_loss: 0.3041 - val_accuracy: 0.8904\n",
            "Работает модель  128-64-32sgd  Итерация  5\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1791 - accuracy: 0.9344 - val_loss: 0.3142 - val_accuracy: 0.8922\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1688 - accuracy: 0.9388 - val_loss: 0.3145 - val_accuracy: 0.8928\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1628 - accuracy: 0.9416 - val_loss: 0.3147 - val_accuracy: 0.8927\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9429 - val_loss: 0.3177 - val_accuracy: 0.8936\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1588 - accuracy: 0.9415 - val_loss: 0.3174 - val_accuracy: 0.8934\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1620 - accuracy: 0.9415 - val_loss: 0.3181 - val_accuracy: 0.8942\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1563 - accuracy: 0.9429 - val_loss: 0.3181 - val_accuracy: 0.8935\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1557 - accuracy: 0.9441 - val_loss: 0.3209 - val_accuracy: 0.8938\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1568 - accuracy: 0.9418 - val_loss: 0.3200 - val_accuracy: 0.8945\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1560 - accuracy: 0.9433 - val_loss: 0.3227 - val_accuracy: 0.8930\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1549 - accuracy: 0.9428 - val_loss: 0.3235 - val_accuracy: 0.8933\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1506 - accuracy: 0.9457 - val_loss: 0.3242 - val_accuracy: 0.8941\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1508 - accuracy: 0.9443 - val_loss: 0.3261 - val_accuracy: 0.8947\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1508 - accuracy: 0.9456 - val_loss: 0.3258 - val_accuracy: 0.8934\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1511 - accuracy: 0.9473 - val_loss: 0.3246 - val_accuracy: 0.8953\n",
            "Работает модель  128-32sgd  Итерация  5\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2068 - accuracy: 0.9273 - val_loss: 0.2956 - val_accuracy: 0.8920\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2018 - accuracy: 0.9290 - val_loss: 0.2951 - val_accuracy: 0.8933\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2012 - accuracy: 0.9309 - val_loss: 0.2958 - val_accuracy: 0.8932\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1968 - accuracy: 0.9317 - val_loss: 0.2956 - val_accuracy: 0.8932\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1965 - accuracy: 0.9308 - val_loss: 0.2958 - val_accuracy: 0.8921\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1927 - accuracy: 0.9331 - val_loss: 0.2958 - val_accuracy: 0.8924\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1970 - accuracy: 0.9311 - val_loss: 0.2960 - val_accuracy: 0.8923\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1981 - accuracy: 0.9322 - val_loss: 0.2960 - val_accuracy: 0.8930\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1966 - accuracy: 0.9325 - val_loss: 0.2962 - val_accuracy: 0.8925\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2013 - accuracy: 0.9293 - val_loss: 0.2965 - val_accuracy: 0.8927\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1950 - accuracy: 0.9329 - val_loss: 0.2961 - val_accuracy: 0.8926\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1937 - accuracy: 0.9323 - val_loss: 0.2964 - val_accuracy: 0.8923\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1954 - accuracy: 0.9319 - val_loss: 0.2962 - val_accuracy: 0.8925\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1961 - accuracy: 0.9320 - val_loss: 0.2965 - val_accuracy: 0.8929\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1905 - accuracy: 0.9339 - val_loss: 0.2963 - val_accuracy: 0.8930\n",
            "Работает модель  128-64-32rms  Итерация  5\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2146 - accuracy: 0.9214 - val_loss: 0.3715 - val_accuracy: 0.8845\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1925 - accuracy: 0.9295 - val_loss: 0.3506 - val_accuracy: 0.8875\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1916 - accuracy: 0.9289 - val_loss: 0.3926 - val_accuracy: 0.8720\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1897 - accuracy: 0.9293 - val_loss: 0.3630 - val_accuracy: 0.8887\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1793 - accuracy: 0.9332 - val_loss: 0.3711 - val_accuracy: 0.8861\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1775 - accuracy: 0.9330 - val_loss: 0.3671 - val_accuracy: 0.8900\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1751 - accuracy: 0.9334 - val_loss: 0.3898 - val_accuracy: 0.8841\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1625 - accuracy: 0.9392 - val_loss: 0.4440 - val_accuracy: 0.8773\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1674 - accuracy: 0.9380 - val_loss: 0.4083 - val_accuracy: 0.8815\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1621 - accuracy: 0.9375 - val_loss: 0.3976 - val_accuracy: 0.8887\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1526 - accuracy: 0.9422 - val_loss: 0.4051 - val_accuracy: 0.8858\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1527 - accuracy: 0.9429 - val_loss: 0.4287 - val_accuracy: 0.8823\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1465 - accuracy: 0.9442 - val_loss: 0.4045 - val_accuracy: 0.8889\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1442 - accuracy: 0.9464 - val_loss: 0.4371 - val_accuracy: 0.8876\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1395 - accuracy: 0.9494 - val_loss: 0.4937 - val_accuracy: 0.8844\n",
            "Работает модель  128-32rms  Итерация  5\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2247 - accuracy: 0.9188 - val_loss: 0.3038 - val_accuracy: 0.8905\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2158 - accuracy: 0.9216 - val_loss: 0.3172 - val_accuracy: 0.8907\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2115 - accuracy: 0.9231 - val_loss: 0.3123 - val_accuracy: 0.8881\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9241 - val_loss: 0.3078 - val_accuracy: 0.8916\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9253 - val_loss: 0.3146 - val_accuracy: 0.8913\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1990 - accuracy: 0.9287 - val_loss: 0.3206 - val_accuracy: 0.8876\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1953 - accuracy: 0.9282 - val_loss: 0.3203 - val_accuracy: 0.8882\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1949 - accuracy: 0.9274 - val_loss: 0.3058 - val_accuracy: 0.8917\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1841 - accuracy: 0.9329 - val_loss: 0.3247 - val_accuracy: 0.8855\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1820 - accuracy: 0.9337 - val_loss: 0.3279 - val_accuracy: 0.8880\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1799 - accuracy: 0.9340 - val_loss: 0.3255 - val_accuracy: 0.8909\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1747 - accuracy: 0.9362 - val_loss: 0.3273 - val_accuracy: 0.8900\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1711 - accuracy: 0.9378 - val_loss: 0.3228 - val_accuracy: 0.8922\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1657 - accuracy: 0.9404 - val_loss: 0.3235 - val_accuracy: 0.8921\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1691 - accuracy: 0.9384 - val_loss: 0.3426 - val_accuracy: 0.8887\n",
            "Работает модель  128-64-32a  Итерация  6\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8988 - accuracy: 0.6942 - val_loss: 0.4707 - val_accuracy: 0.8347\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4243 - accuracy: 0.8478 - val_loss: 0.4041 - val_accuracy: 0.8568\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3791 - accuracy: 0.8646 - val_loss: 0.3674 - val_accuracy: 0.8696\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3347 - accuracy: 0.8777 - val_loss: 0.3622 - val_accuracy: 0.8675\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3182 - accuracy: 0.8834 - val_loss: 0.3419 - val_accuracy: 0.8783\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2940 - accuracy: 0.8921 - val_loss: 0.3444 - val_accuracy: 0.8773\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2810 - accuracy: 0.8958 - val_loss: 0.3685 - val_accuracy: 0.8737\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2693 - accuracy: 0.9008 - val_loss: 0.3467 - val_accuracy: 0.8782\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2594 - accuracy: 0.9022 - val_loss: 0.3311 - val_accuracy: 0.8843\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2427 - accuracy: 0.9103 - val_loss: 0.3322 - val_accuracy: 0.8848\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2415 - accuracy: 0.9092 - val_loss: 0.3306 - val_accuracy: 0.8825\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2251 - accuracy: 0.9168 - val_loss: 0.3421 - val_accuracy: 0.8836\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2166 - accuracy: 0.9202 - val_loss: 0.3442 - val_accuracy: 0.8817\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2130 - accuracy: 0.9201 - val_loss: 0.3287 - val_accuracy: 0.8876\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2034 - accuracy: 0.9252 - val_loss: 0.3352 - val_accuracy: 0.8837\n",
            "Работает модель  128-64-32a  Итерация  6\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2540 - accuracy: 0.6575 - val_loss: 0.5432 - val_accuracy: 0.8274\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4964 - accuracy: 0.8423 - val_loss: 0.4327 - val_accuracy: 0.8518\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - accuracy: 0.8608 - val_loss: 0.3919 - val_accuracy: 0.8639\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3656 - accuracy: 0.8732 - val_loss: 0.3893 - val_accuracy: 0.8614\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8777 - val_loss: 0.3539 - val_accuracy: 0.8753\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.8910 - val_loss: 0.3433 - val_accuracy: 0.8780\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3049 - accuracy: 0.8915 - val_loss: 0.3390 - val_accuracy: 0.8787\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2941 - accuracy: 0.8936 - val_loss: 0.3441 - val_accuracy: 0.8742\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2765 - accuracy: 0.8997 - val_loss: 0.3364 - val_accuracy: 0.8802\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2628 - accuracy: 0.9060 - val_loss: 0.3157 - val_accuracy: 0.8848\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2603 - accuracy: 0.9053 - val_loss: 0.3277 - val_accuracy: 0.8818\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2535 - accuracy: 0.9082 - val_loss: 0.3097 - val_accuracy: 0.8875\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2415 - accuracy: 0.9134 - val_loss: 0.3105 - val_accuracy: 0.8883\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2302 - accuracy: 0.9149 - val_loss: 0.3238 - val_accuracy: 0.8800\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2297 - accuracy: 0.9168 - val_loss: 0.3090 - val_accuracy: 0.8879\n",
            "Работает модель  128-64-32sgd  Итерация  6\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1829 - accuracy: 0.9333 - val_loss: 0.3161 - val_accuracy: 0.8926\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1665 - accuracy: 0.9397 - val_loss: 0.3154 - val_accuracy: 0.8928\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1632 - accuracy: 0.9405 - val_loss: 0.3165 - val_accuracy: 0.8929\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1582 - accuracy: 0.9430 - val_loss: 0.3168 - val_accuracy: 0.8942\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1576 - accuracy: 0.9421 - val_loss: 0.3187 - val_accuracy: 0.8940\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1590 - accuracy: 0.9414 - val_loss: 0.3205 - val_accuracy: 0.8940\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1552 - accuracy: 0.9435 - val_loss: 0.3260 - val_accuracy: 0.8916\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1491 - accuracy: 0.9458 - val_loss: 0.3222 - val_accuracy: 0.8934\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1516 - accuracy: 0.9446 - val_loss: 0.3221 - val_accuracy: 0.8937\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1525 - accuracy: 0.9456 - val_loss: 0.3244 - val_accuracy: 0.8946\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1498 - accuracy: 0.9456 - val_loss: 0.3247 - val_accuracy: 0.8928\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1502 - accuracy: 0.9449 - val_loss: 0.3255 - val_accuracy: 0.8929\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1534 - accuracy: 0.9455 - val_loss: 0.3259 - val_accuracy: 0.8935\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1511 - accuracy: 0.9447 - val_loss: 0.3265 - val_accuracy: 0.8945\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1496 - accuracy: 0.9458 - val_loss: 0.3281 - val_accuracy: 0.8933\n",
            "Работает модель  128-32sgd  Итерация  6\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2095 - accuracy: 0.9254 - val_loss: 0.2993 - val_accuracy: 0.8921\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1998 - accuracy: 0.9292 - val_loss: 0.2987 - val_accuracy: 0.8923\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2009 - accuracy: 0.9302 - val_loss: 0.2982 - val_accuracy: 0.8923\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1955 - accuracy: 0.9301 - val_loss: 0.2979 - val_accuracy: 0.8932\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1980 - accuracy: 0.9310 - val_loss: 0.2981 - val_accuracy: 0.8928\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1966 - accuracy: 0.9308 - val_loss: 0.2979 - val_accuracy: 0.8928\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1963 - accuracy: 0.9315 - val_loss: 0.2978 - val_accuracy: 0.8928\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1963 - accuracy: 0.9312 - val_loss: 0.2978 - val_accuracy: 0.8938\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1982 - accuracy: 0.9297 - val_loss: 0.2977 - val_accuracy: 0.8931\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1930 - accuracy: 0.9316 - val_loss: 0.2979 - val_accuracy: 0.8932\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1959 - accuracy: 0.9313 - val_loss: 0.2978 - val_accuracy: 0.8937\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1970 - accuracy: 0.9311 - val_loss: 0.2979 - val_accuracy: 0.8932\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1920 - accuracy: 0.9323 - val_loss: 0.2978 - val_accuracy: 0.8934\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1935 - accuracy: 0.9327 - val_loss: 0.2979 - val_accuracy: 0.8937\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1936 - accuracy: 0.9328 - val_loss: 0.2978 - val_accuracy: 0.8937\n",
            "Работает модель  128-64-32rms  Итерация  6\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2133 - accuracy: 0.9204 - val_loss: 0.3638 - val_accuracy: 0.8848\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1962 - accuracy: 0.9245 - val_loss: 0.3432 - val_accuracy: 0.8871\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1939 - accuracy: 0.9283 - val_loss: 0.3672 - val_accuracy: 0.8788\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1881 - accuracy: 0.9288 - val_loss: 0.3738 - val_accuracy: 0.8866\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1825 - accuracy: 0.9315 - val_loss: 0.3827 - val_accuracy: 0.8893\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1762 - accuracy: 0.9350 - val_loss: 0.4095 - val_accuracy: 0.8813\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1726 - accuracy: 0.9357 - val_loss: 0.3901 - val_accuracy: 0.8865\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1665 - accuracy: 0.9388 - val_loss: 0.3800 - val_accuracy: 0.8818\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1643 - accuracy: 0.9394 - val_loss: 0.4125 - val_accuracy: 0.8838\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1574 - accuracy: 0.9413 - val_loss: 0.4150 - val_accuracy: 0.8788\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1532 - accuracy: 0.9415 - val_loss: 0.4697 - val_accuracy: 0.8692\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1466 - accuracy: 0.9458 - val_loss: 0.4138 - val_accuracy: 0.8788\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1512 - accuracy: 0.9429 - val_loss: 0.4289 - val_accuracy: 0.8857\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1437 - accuracy: 0.9452 - val_loss: 0.4211 - val_accuracy: 0.8854\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1432 - accuracy: 0.9453 - val_loss: 0.4764 - val_accuracy: 0.8709\n",
            "Работает модель  128-32rms  Итерация  6\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2233 - accuracy: 0.9184 - val_loss: 0.3159 - val_accuracy: 0.8854\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2149 - accuracy: 0.9197 - val_loss: 0.3109 - val_accuracy: 0.8863\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9240 - val_loss: 0.3194 - val_accuracy: 0.8861\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9225 - val_loss: 0.3273 - val_accuracy: 0.8869\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2001 - accuracy: 0.9282 - val_loss: 0.3086 - val_accuracy: 0.8898\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1962 - accuracy: 0.9285 - val_loss: 0.3272 - val_accuracy: 0.8860\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1930 - accuracy: 0.9303 - val_loss: 0.3266 - val_accuracy: 0.8848\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1958 - accuracy: 0.9293 - val_loss: 0.3192 - val_accuracy: 0.8910\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1826 - accuracy: 0.9335 - val_loss: 0.3254 - val_accuracy: 0.8909\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1795 - accuracy: 0.9368 - val_loss: 0.3130 - val_accuracy: 0.8923\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1756 - accuracy: 0.9354 - val_loss: 0.3187 - val_accuracy: 0.8909\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1763 - accuracy: 0.9363 - val_loss: 0.3342 - val_accuracy: 0.8873\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1690 - accuracy: 0.9385 - val_loss: 0.3293 - val_accuracy: 0.8920\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1677 - accuracy: 0.9393 - val_loss: 0.3408 - val_accuracy: 0.8854\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1583 - accuracy: 0.9428 - val_loss: 0.3409 - val_accuracy: 0.8874\n",
            "Работает модель  128-64-32a  Итерация  7\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8972 - accuracy: 0.6914 - val_loss: 0.4366 - val_accuracy: 0.8465\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4192 - accuracy: 0.8503 - val_loss: 0.4134 - val_accuracy: 0.8518\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3721 - accuracy: 0.8648 - val_loss: 0.3827 - val_accuracy: 0.8633\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8756 - val_loss: 0.3457 - val_accuracy: 0.8737\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3053 - accuracy: 0.8863 - val_loss: 0.3415 - val_accuracy: 0.8761\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2945 - accuracy: 0.8899 - val_loss: 0.3463 - val_accuracy: 0.8777\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2805 - accuracy: 0.8965 - val_loss: 0.3505 - val_accuracy: 0.8742\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2666 - accuracy: 0.9014 - val_loss: 0.3508 - val_accuracy: 0.8757\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2490 - accuracy: 0.9077 - val_loss: 0.3357 - val_accuracy: 0.8817\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2449 - accuracy: 0.9113 - val_loss: 0.3396 - val_accuracy: 0.8752\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2380 - accuracy: 0.9121 - val_loss: 0.3254 - val_accuracy: 0.8859\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2232 - accuracy: 0.9185 - val_loss: 0.3347 - val_accuracy: 0.8822\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2191 - accuracy: 0.9200 - val_loss: 0.3488 - val_accuracy: 0.8784\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2123 - accuracy: 0.9208 - val_loss: 0.3400 - val_accuracy: 0.8857\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2012 - accuracy: 0.9244 - val_loss: 0.3190 - val_accuracy: 0.8878\n",
            "Работает модель  128-64-32a  Итерация  7\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2382 - accuracy: 0.6596 - val_loss: 0.5366 - val_accuracy: 0.8326\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4972 - accuracy: 0.8410 - val_loss: 0.4175 - val_accuracy: 0.8587\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4029 - accuracy: 0.8634 - val_loss: 0.3773 - val_accuracy: 0.8692\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3538 - accuracy: 0.8782 - val_loss: 0.3674 - val_accuracy: 0.8709\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3418 - accuracy: 0.8797 - val_loss: 0.3468 - val_accuracy: 0.8760\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3180 - accuracy: 0.8875 - val_loss: 0.3374 - val_accuracy: 0.8783\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2944 - accuracy: 0.8961 - val_loss: 0.3490 - val_accuracy: 0.8716\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2935 - accuracy: 0.8924 - val_loss: 0.3271 - val_accuracy: 0.8808\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2773 - accuracy: 0.8989 - val_loss: 0.3207 - val_accuracy: 0.8833\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2675 - accuracy: 0.9053 - val_loss: 0.3308 - val_accuracy: 0.8818\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2590 - accuracy: 0.9070 - val_loss: 0.3118 - val_accuracy: 0.8865\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2500 - accuracy: 0.9094 - val_loss: 0.3161 - val_accuracy: 0.8851\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2447 - accuracy: 0.9116 - val_loss: 0.3170 - val_accuracy: 0.8815\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2358 - accuracy: 0.9150 - val_loss: 0.3156 - val_accuracy: 0.8863\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2262 - accuracy: 0.9202 - val_loss: 0.3055 - val_accuracy: 0.8895\n",
            "Работает модель  128-64-32sgd  Итерация  7\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1730 - accuracy: 0.9381 - val_loss: 0.3124 - val_accuracy: 0.8917\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1619 - accuracy: 0.9413 - val_loss: 0.3123 - val_accuracy: 0.8927\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1611 - accuracy: 0.9411 - val_loss: 0.3137 - val_accuracy: 0.8935\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1578 - accuracy: 0.9420 - val_loss: 0.3141 - val_accuracy: 0.8938\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1576 - accuracy: 0.9427 - val_loss: 0.3173 - val_accuracy: 0.8931\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1594 - accuracy: 0.9419 - val_loss: 0.3163 - val_accuracy: 0.8955\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1559 - accuracy: 0.9427 - val_loss: 0.3180 - val_accuracy: 0.8928\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1506 - accuracy: 0.9450 - val_loss: 0.3188 - val_accuracy: 0.8945\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1510 - accuracy: 0.9447 - val_loss: 0.3217 - val_accuracy: 0.8917\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1530 - accuracy: 0.9449 - val_loss: 0.3241 - val_accuracy: 0.8937\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1516 - accuracy: 0.9441 - val_loss: 0.3220 - val_accuracy: 0.8947\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1530 - accuracy: 0.9434 - val_loss: 0.3236 - val_accuracy: 0.8940\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1472 - accuracy: 0.9464 - val_loss: 0.3261 - val_accuracy: 0.8932\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1512 - accuracy: 0.9448 - val_loss: 0.3292 - val_accuracy: 0.8911\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1484 - accuracy: 0.9461 - val_loss: 0.3290 - val_accuracy: 0.8917\n",
            "Работает модель  128-32sgd  Итерация  7\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2086 - accuracy: 0.9263 - val_loss: 0.2964 - val_accuracy: 0.8948\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1964 - accuracy: 0.9302 - val_loss: 0.2959 - val_accuracy: 0.8941\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1956 - accuracy: 0.9311 - val_loss: 0.2961 - val_accuracy: 0.8930\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1970 - accuracy: 0.9303 - val_loss: 0.2958 - val_accuracy: 0.8941\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1954 - accuracy: 0.9318 - val_loss: 0.2956 - val_accuracy: 0.8954\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1955 - accuracy: 0.9308 - val_loss: 0.2956 - val_accuracy: 0.8946\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1955 - accuracy: 0.9314 - val_loss: 0.2955 - val_accuracy: 0.8946\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1940 - accuracy: 0.9320 - val_loss: 0.2957 - val_accuracy: 0.8941\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1955 - accuracy: 0.9298 - val_loss: 0.2958 - val_accuracy: 0.8940\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1956 - accuracy: 0.9310 - val_loss: 0.2958 - val_accuracy: 0.8939\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1961 - accuracy: 0.9307 - val_loss: 0.2959 - val_accuracy: 0.8937\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1961 - accuracy: 0.9299 - val_loss: 0.2960 - val_accuracy: 0.8933\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1945 - accuracy: 0.9317 - val_loss: 0.2960 - val_accuracy: 0.8950\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1869 - accuracy: 0.9345 - val_loss: 0.2957 - val_accuracy: 0.8947\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1956 - accuracy: 0.9317 - val_loss: 0.2960 - val_accuracy: 0.8941\n",
            "Работает модель  128-64-32rms  Итерация  7\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2165 - accuracy: 0.9188 - val_loss: 0.3524 - val_accuracy: 0.8885\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1981 - accuracy: 0.9236 - val_loss: 0.3635 - val_accuracy: 0.8848\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1981 - accuracy: 0.9250 - val_loss: 0.3428 - val_accuracy: 0.8882\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1904 - accuracy: 0.9278 - val_loss: 0.3639 - val_accuracy: 0.8857\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1837 - accuracy: 0.9316 - val_loss: 0.3797 - val_accuracy: 0.8813\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1777 - accuracy: 0.9330 - val_loss: 0.3698 - val_accuracy: 0.8842\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1708 - accuracy: 0.9347 - val_loss: 0.3714 - val_accuracy: 0.8893\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1677 - accuracy: 0.9362 - val_loss: 0.3759 - val_accuracy: 0.8817\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1654 - accuracy: 0.9375 - val_loss: 0.3930 - val_accuracy: 0.8858\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1576 - accuracy: 0.9403 - val_loss: 0.4081 - val_accuracy: 0.8821\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1551 - accuracy: 0.9421 - val_loss: 0.4258 - val_accuracy: 0.8847\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1530 - accuracy: 0.9424 - val_loss: 0.3898 - val_accuracy: 0.8880\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1482 - accuracy: 0.9442 - val_loss: 0.4138 - val_accuracy: 0.8847\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1459 - accuracy: 0.9441 - val_loss: 0.4254 - val_accuracy: 0.8867\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1402 - accuracy: 0.9482 - val_loss: 0.4283 - val_accuracy: 0.8877\n",
            "Работает модель  128-32rms  Итерация  7\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2174 - accuracy: 0.9218 - val_loss: 0.3159 - val_accuracy: 0.8908\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2151 - accuracy: 0.9219 - val_loss: 0.3030 - val_accuracy: 0.8913\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9243 - val_loss: 0.3139 - val_accuracy: 0.8907\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2004 - accuracy: 0.9261 - val_loss: 0.3285 - val_accuracy: 0.8872\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9269 - val_loss: 0.3039 - val_accuracy: 0.8905\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1994 - accuracy: 0.9279 - val_loss: 0.3096 - val_accuracy: 0.8910\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1951 - accuracy: 0.9300 - val_loss: 0.3188 - val_accuracy: 0.8893\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1900 - accuracy: 0.9318 - val_loss: 0.3266 - val_accuracy: 0.8867\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1856 - accuracy: 0.9333 - val_loss: 0.3278 - val_accuracy: 0.8853\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1808 - accuracy: 0.9338 - val_loss: 0.3152 - val_accuracy: 0.8905\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1801 - accuracy: 0.9361 - val_loss: 0.3150 - val_accuracy: 0.8928\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1808 - accuracy: 0.9353 - val_loss: 0.3346 - val_accuracy: 0.8903\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1694 - accuracy: 0.9391 - val_loss: 0.3287 - val_accuracy: 0.8903\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1678 - accuracy: 0.9404 - val_loss: 0.3298 - val_accuracy: 0.8899\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1639 - accuracy: 0.9410 - val_loss: 0.3339 - val_accuracy: 0.8909\n",
            "Работает модель  128-64-32a  Итерация  8\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8754 - accuracy: 0.6875 - val_loss: 0.4422 - val_accuracy: 0.8447\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4262 - accuracy: 0.8492 - val_loss: 0.3925 - val_accuracy: 0.8620\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3692 - accuracy: 0.8661 - val_loss: 0.3774 - val_accuracy: 0.8647\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3309 - accuracy: 0.8799 - val_loss: 0.3704 - val_accuracy: 0.8680\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3126 - accuracy: 0.8857 - val_loss: 0.3642 - val_accuracy: 0.8690\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2924 - accuracy: 0.8919 - val_loss: 0.3417 - val_accuracy: 0.8785\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2801 - accuracy: 0.8942 - val_loss: 0.3316 - val_accuracy: 0.8826\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2658 - accuracy: 0.9015 - val_loss: 0.3300 - val_accuracy: 0.8813\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2605 - accuracy: 0.9037 - val_loss: 0.3273 - val_accuracy: 0.8828\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2515 - accuracy: 0.9074 - val_loss: 0.3520 - val_accuracy: 0.8792\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2360 - accuracy: 0.9118 - val_loss: 0.3512 - val_accuracy: 0.8795\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2245 - accuracy: 0.9163 - val_loss: 0.3349 - val_accuracy: 0.8867\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2199 - accuracy: 0.9169 - val_loss: 0.3392 - val_accuracy: 0.8878\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2121 - accuracy: 0.9210 - val_loss: 0.3278 - val_accuracy: 0.8897\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2008 - accuracy: 0.9252 - val_loss: 0.3352 - val_accuracy: 0.8879\n",
            "Работает модель  128-64-32a  Итерация  8\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1981 - accuracy: 0.6663 - val_loss: 0.5118 - val_accuracy: 0.8350\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4748 - accuracy: 0.8465 - val_loss: 0.4156 - val_accuracy: 0.8536\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3915 - accuracy: 0.8644 - val_loss: 0.3799 - val_accuracy: 0.8673\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3528 - accuracy: 0.8766 - val_loss: 0.3787 - val_accuracy: 0.8610\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3371 - accuracy: 0.8803 - val_loss: 0.3493 - val_accuracy: 0.8744\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3199 - accuracy: 0.8869 - val_loss: 0.3378 - val_accuracy: 0.8772\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3027 - accuracy: 0.8925 - val_loss: 0.3347 - val_accuracy: 0.8803\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2936 - accuracy: 0.8948 - val_loss: 0.3225 - val_accuracy: 0.8823\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2783 - accuracy: 0.8987 - val_loss: 0.3234 - val_accuracy: 0.8832\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2669 - accuracy: 0.9036 - val_loss: 0.3172 - val_accuracy: 0.8848\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2598 - accuracy: 0.9050 - val_loss: 0.3228 - val_accuracy: 0.8813\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2459 - accuracy: 0.9103 - val_loss: 0.3040 - val_accuracy: 0.8907\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2364 - accuracy: 0.9140 - val_loss: 0.3166 - val_accuracy: 0.8853\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2360 - accuracy: 0.9120 - val_loss: 0.3115 - val_accuracy: 0.8866\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2312 - accuracy: 0.9162 - val_loss: 0.3132 - val_accuracy: 0.8885\n",
            "Работает модель  128-64-32sgd  Итерация  8\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1756 - accuracy: 0.9351 - val_loss: 0.3172 - val_accuracy: 0.8942\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1669 - accuracy: 0.9394 - val_loss: 0.3195 - val_accuracy: 0.8938\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1647 - accuracy: 0.9389 - val_loss: 0.3195 - val_accuracy: 0.8947\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1606 - accuracy: 0.9412 - val_loss: 0.3209 - val_accuracy: 0.8941\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1586 - accuracy: 0.9417 - val_loss: 0.3219 - val_accuracy: 0.8939\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9414 - val_loss: 0.3233 - val_accuracy: 0.8942\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1579 - accuracy: 0.9415 - val_loss: 0.3274 - val_accuracy: 0.8944\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1532 - accuracy: 0.9447 - val_loss: 0.3259 - val_accuracy: 0.8927\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1576 - accuracy: 0.9422 - val_loss: 0.3253 - val_accuracy: 0.8943\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1542 - accuracy: 0.9447 - val_loss: 0.3283 - val_accuracy: 0.8935\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1548 - accuracy: 0.9436 - val_loss: 0.3295 - val_accuracy: 0.8928\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1564 - accuracy: 0.9427 - val_loss: 0.3269 - val_accuracy: 0.8943\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1489 - accuracy: 0.9457 - val_loss: 0.3283 - val_accuracy: 0.8939\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1537 - accuracy: 0.9447 - val_loss: 0.3303 - val_accuracy: 0.8943\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1533 - accuracy: 0.9441 - val_loss: 0.3308 - val_accuracy: 0.8932\n",
            "Работает модель  128-32sgd  Итерация  8\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2083 - accuracy: 0.9252 - val_loss: 0.2984 - val_accuracy: 0.8924\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2013 - accuracy: 0.9279 - val_loss: 0.2973 - val_accuracy: 0.8927\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1970 - accuracy: 0.9313 - val_loss: 0.2965 - val_accuracy: 0.8934\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1975 - accuracy: 0.9290 - val_loss: 0.2960 - val_accuracy: 0.8938\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1984 - accuracy: 0.9296 - val_loss: 0.2962 - val_accuracy: 0.8933\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1962 - accuracy: 0.9303 - val_loss: 0.2958 - val_accuracy: 0.8939\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2009 - accuracy: 0.9290 - val_loss: 0.2963 - val_accuracy: 0.8932\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1969 - accuracy: 0.9288 - val_loss: 0.2961 - val_accuracy: 0.8928\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1935 - accuracy: 0.9306 - val_loss: 0.2961 - val_accuracy: 0.8932\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1955 - accuracy: 0.9301 - val_loss: 0.2960 - val_accuracy: 0.8934\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1981 - accuracy: 0.9290 - val_loss: 0.2960 - val_accuracy: 0.8928\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1895 - accuracy: 0.9332 - val_loss: 0.2959 - val_accuracy: 0.8934\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1941 - accuracy: 0.9304 - val_loss: 0.2959 - val_accuracy: 0.8928\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1956 - accuracy: 0.9305 - val_loss: 0.2960 - val_accuracy: 0.8931\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1954 - accuracy: 0.9317 - val_loss: 0.2961 - val_accuracy: 0.8928\n",
            "Работает модель  128-64-32rms  Итерация  8\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2176 - accuracy: 0.9201 - val_loss: 0.3770 - val_accuracy: 0.8770\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1977 - accuracy: 0.9258 - val_loss: 0.3641 - val_accuracy: 0.8796\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1937 - accuracy: 0.9274 - val_loss: 0.3806 - val_accuracy: 0.8832\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1891 - accuracy: 0.9290 - val_loss: 0.3830 - val_accuracy: 0.8838\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1850 - accuracy: 0.9296 - val_loss: 0.3648 - val_accuracy: 0.8894\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1774 - accuracy: 0.9338 - val_loss: 0.3909 - val_accuracy: 0.8867\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1729 - accuracy: 0.9354 - val_loss: 0.3868 - val_accuracy: 0.8863\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1671 - accuracy: 0.9377 - val_loss: 0.3706 - val_accuracy: 0.8888\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1609 - accuracy: 0.9403 - val_loss: 0.4415 - val_accuracy: 0.8838\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1617 - accuracy: 0.9390 - val_loss: 0.4400 - val_accuracy: 0.8807\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1565 - accuracy: 0.9430 - val_loss: 0.4211 - val_accuracy: 0.8878\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1516 - accuracy: 0.9437 - val_loss: 0.4652 - val_accuracy: 0.8842\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1467 - accuracy: 0.9447 - val_loss: 0.4146 - val_accuracy: 0.8888\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1460 - accuracy: 0.9454 - val_loss: 0.4338 - val_accuracy: 0.8911\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1432 - accuracy: 0.9461 - val_loss: 0.4599 - val_accuracy: 0.8890\n",
            "Работает модель  128-32rms  Итерация  8\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2266 - accuracy: 0.9161 - val_loss: 0.3223 - val_accuracy: 0.8866\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2163 - accuracy: 0.9203 - val_loss: 0.3107 - val_accuracy: 0.8941\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2122 - accuracy: 0.9228 - val_loss: 0.3144 - val_accuracy: 0.8881\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9228 - val_loss: 0.3216 - val_accuracy: 0.8878\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9247 - val_loss: 0.3257 - val_accuracy: 0.8854\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1936 - accuracy: 0.9283 - val_loss: 0.3199 - val_accuracy: 0.8867\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1986 - accuracy: 0.9273 - val_loss: 0.3120 - val_accuracy: 0.8913\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1846 - accuracy: 0.9340 - val_loss: 0.3105 - val_accuracy: 0.8918\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1816 - accuracy: 0.9332 - val_loss: 0.3172 - val_accuracy: 0.8929\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1820 - accuracy: 0.9346 - val_loss: 0.3140 - val_accuracy: 0.8936\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1760 - accuracy: 0.9350 - val_loss: 0.3198 - val_accuracy: 0.8890\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1733 - accuracy: 0.9362 - val_loss: 0.3226 - val_accuracy: 0.8918\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1725 - accuracy: 0.9381 - val_loss: 0.3299 - val_accuracy: 0.8888\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1731 - accuracy: 0.9358 - val_loss: 0.3265 - val_accuracy: 0.8933\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1649 - accuracy: 0.9403 - val_loss: 0.3214 - val_accuracy: 0.8932\n",
            "Работает модель  128-64-32a  Итерация  9\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9828 - accuracy: 0.6724 - val_loss: 0.4597 - val_accuracy: 0.8361\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4205 - accuracy: 0.8529 - val_loss: 0.3968 - val_accuracy: 0.8559\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3648 - accuracy: 0.8672 - val_loss: 0.4008 - val_accuracy: 0.8584\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.8768 - val_loss: 0.3575 - val_accuracy: 0.8740\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3201 - accuracy: 0.8837 - val_loss: 0.3426 - val_accuracy: 0.8755\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2959 - accuracy: 0.8883 - val_loss: 0.3292 - val_accuracy: 0.8813\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2784 - accuracy: 0.8991 - val_loss: 0.3463 - val_accuracy: 0.8763\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2633 - accuracy: 0.9022 - val_loss: 0.3415 - val_accuracy: 0.8771\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2562 - accuracy: 0.9039 - val_loss: 0.3388 - val_accuracy: 0.8816\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2430 - accuracy: 0.9103 - val_loss: 0.3325 - val_accuracy: 0.8847\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2335 - accuracy: 0.9144 - val_loss: 0.3214 - val_accuracy: 0.8875\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2308 - accuracy: 0.9143 - val_loss: 0.3285 - val_accuracy: 0.8831\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2188 - accuracy: 0.9195 - val_loss: 0.3160 - val_accuracy: 0.8888\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9248 - val_loss: 0.3378 - val_accuracy: 0.8873\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1973 - accuracy: 0.9260 - val_loss: 0.3287 - val_accuracy: 0.8877\n",
            "Работает модель  128-64-32a  Итерация  9\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2449 - accuracy: 0.6482 - val_loss: 0.5480 - val_accuracy: 0.8231\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5014 - accuracy: 0.8397 - val_loss: 0.4285 - val_accuracy: 0.8552\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4046 - accuracy: 0.8637 - val_loss: 0.3955 - val_accuracy: 0.8630\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3709 - accuracy: 0.8689 - val_loss: 0.3685 - val_accuracy: 0.8687\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3383 - accuracy: 0.8812 - val_loss: 0.3538 - val_accuracy: 0.8731\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3170 - accuracy: 0.8878 - val_loss: 0.3455 - val_accuracy: 0.8777\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3029 - accuracy: 0.8920 - val_loss: 0.3451 - val_accuracy: 0.8742\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2901 - accuracy: 0.8939 - val_loss: 0.3357 - val_accuracy: 0.8788\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2785 - accuracy: 0.9005 - val_loss: 0.3270 - val_accuracy: 0.8821\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2616 - accuracy: 0.9047 - val_loss: 0.3242 - val_accuracy: 0.8830\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2564 - accuracy: 0.9088 - val_loss: 0.3147 - val_accuracy: 0.8864\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2447 - accuracy: 0.9123 - val_loss: 0.3145 - val_accuracy: 0.8869\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2432 - accuracy: 0.9119 - val_loss: 0.3067 - val_accuracy: 0.8884\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2356 - accuracy: 0.9155 - val_loss: 0.3107 - val_accuracy: 0.8878\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2244 - accuracy: 0.9198 - val_loss: 0.3187 - val_accuracy: 0.8872\n",
            "Работает модель  128-64-32sgd  Итерация  9\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1768 - accuracy: 0.9368 - val_loss: 0.3126 - val_accuracy: 0.8946\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1624 - accuracy: 0.9406 - val_loss: 0.3152 - val_accuracy: 0.8943\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1619 - accuracy: 0.9410 - val_loss: 0.3147 - val_accuracy: 0.8946\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1603 - accuracy: 0.9422 - val_loss: 0.3190 - val_accuracy: 0.8933\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1575 - accuracy: 0.9410 - val_loss: 0.3169 - val_accuracy: 0.8943\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1565 - accuracy: 0.9438 - val_loss: 0.3192 - val_accuracy: 0.8938\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1517 - accuracy: 0.9453 - val_loss: 0.3178 - val_accuracy: 0.8947\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1552 - accuracy: 0.9437 - val_loss: 0.3223 - val_accuracy: 0.8935\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1512 - accuracy: 0.9451 - val_loss: 0.3209 - val_accuracy: 0.8938\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1497 - accuracy: 0.9458 - val_loss: 0.3199 - val_accuracy: 0.8953\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1522 - accuracy: 0.9445 - val_loss: 0.3215 - val_accuracy: 0.8954\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1530 - accuracy: 0.9441 - val_loss: 0.3257 - val_accuracy: 0.8941\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1518 - accuracy: 0.9448 - val_loss: 0.3236 - val_accuracy: 0.8943\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9446 - val_loss: 0.3239 - val_accuracy: 0.8942\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1442 - accuracy: 0.9475 - val_loss: 0.3249 - val_accuracy: 0.8938\n",
            "Работает модель  128-32sgd  Итерация  9\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2129 - accuracy: 0.9250 - val_loss: 0.2993 - val_accuracy: 0.8942\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1987 - accuracy: 0.9303 - val_loss: 0.2991 - val_accuracy: 0.8947\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2022 - accuracy: 0.9299 - val_loss: 0.2990 - val_accuracy: 0.8947\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1981 - accuracy: 0.9307 - val_loss: 0.2986 - val_accuracy: 0.8951\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1984 - accuracy: 0.9305 - val_loss: 0.2982 - val_accuracy: 0.8952\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1984 - accuracy: 0.9309 - val_loss: 0.2983 - val_accuracy: 0.8944\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1941 - accuracy: 0.9323 - val_loss: 0.2981 - val_accuracy: 0.8947\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1999 - accuracy: 0.9300 - val_loss: 0.2980 - val_accuracy: 0.8950\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1948 - accuracy: 0.9327 - val_loss: 0.2981 - val_accuracy: 0.8948\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1907 - accuracy: 0.9331 - val_loss: 0.2976 - val_accuracy: 0.8946\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1958 - accuracy: 0.9326 - val_loss: 0.2982 - val_accuracy: 0.8943\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1952 - accuracy: 0.9315 - val_loss: 0.2977 - val_accuracy: 0.8950\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1920 - accuracy: 0.9329 - val_loss: 0.2978 - val_accuracy: 0.8945\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1909 - accuracy: 0.9342 - val_loss: 0.2977 - val_accuracy: 0.8951\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1883 - accuracy: 0.9349 - val_loss: 0.2977 - val_accuracy: 0.8947\n",
            "Работает модель  128-64-32rms  Итерация  9\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2161 - accuracy: 0.9185 - val_loss: 0.3885 - val_accuracy: 0.8780\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1971 - accuracy: 0.9269 - val_loss: 0.3461 - val_accuracy: 0.8861\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1877 - accuracy: 0.9285 - val_loss: 0.3580 - val_accuracy: 0.8877\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1870 - accuracy: 0.9293 - val_loss: 0.3571 - val_accuracy: 0.8824\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1833 - accuracy: 0.9309 - val_loss: 0.3945 - val_accuracy: 0.8848\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1769 - accuracy: 0.9343 - val_loss: 0.3658 - val_accuracy: 0.8860\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1690 - accuracy: 0.9374 - val_loss: 0.3678 - val_accuracy: 0.8903\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1688 - accuracy: 0.9372 - val_loss: 0.3820 - val_accuracy: 0.8867\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1597 - accuracy: 0.9394 - val_loss: 0.3835 - val_accuracy: 0.8891\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1622 - accuracy: 0.9384 - val_loss: 0.3868 - val_accuracy: 0.8913\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1582 - accuracy: 0.9404 - val_loss: 0.4141 - val_accuracy: 0.8849\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1550 - accuracy: 0.9408 - val_loss: 0.4052 - val_accuracy: 0.8878\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1468 - accuracy: 0.9447 - val_loss: 0.4343 - val_accuracy: 0.8792\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1439 - accuracy: 0.9449 - val_loss: 0.4293 - val_accuracy: 0.8876\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1466 - accuracy: 0.9447 - val_loss: 0.4787 - val_accuracy: 0.8820\n",
            "Работает модель  128-32rms  Итерация  9\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2222 - accuracy: 0.9167 - val_loss: 0.3089 - val_accuracy: 0.8923\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2154 - accuracy: 0.9216 - val_loss: 0.3152 - val_accuracy: 0.8861\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9246 - val_loss: 0.3160 - val_accuracy: 0.8880\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9231 - val_loss: 0.3155 - val_accuracy: 0.8894\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2028 - accuracy: 0.9273 - val_loss: 0.3171 - val_accuracy: 0.8868\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2002 - accuracy: 0.9287 - val_loss: 0.3249 - val_accuracy: 0.8875\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1901 - accuracy: 0.9312 - val_loss: 0.3195 - val_accuracy: 0.8894\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1921 - accuracy: 0.9301 - val_loss: 0.3446 - val_accuracy: 0.8842\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1893 - accuracy: 0.9312 - val_loss: 0.3266 - val_accuracy: 0.8894\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1762 - accuracy: 0.9369 - val_loss: 0.3267 - val_accuracy: 0.8895\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1777 - accuracy: 0.9357 - val_loss: 0.3300 - val_accuracy: 0.8886\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1664 - accuracy: 0.9391 - val_loss: 0.3319 - val_accuracy: 0.8863\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1677 - accuracy: 0.9407 - val_loss: 0.3225 - val_accuracy: 0.8908\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1649 - accuracy: 0.9411 - val_loss: 0.3338 - val_accuracy: 0.8907\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1622 - accuracy: 0.9437 - val_loss: 0.3385 - val_accuracy: 0.8891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "S6Pwob14En4u",
        "outputId": "5866a434-77ac-4040-d03b-dba43b668e79"
      },
      "source": [
        "test_3a_df.astype(np.float64).describe()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>128-64-32a</th>\n",
              "      <th>128-32a</th>\n",
              "      <th>128-64-32sgd</th>\n",
              "      <th>128-32sgd</th>\n",
              "      <th>128-64-32rms</th>\n",
              "      <th>128-32rms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.918658</td>\n",
              "      <td>0.914623</td>\n",
              "      <td>0.935365</td>\n",
              "      <td>0.923778</td>\n",
              "      <td>0.932525</td>\n",
              "      <td>0.931282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.002815</td>\n",
              "      <td>0.002809</td>\n",
              "      <td>0.000733</td>\n",
              "      <td>0.001201</td>\n",
              "      <td>0.006973</td>\n",
              "      <td>0.004279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.913100</td>\n",
              "      <td>0.909633</td>\n",
              "      <td>0.934250</td>\n",
              "      <td>0.921983</td>\n",
              "      <td>0.921100</td>\n",
              "      <td>0.922900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.917413</td>\n",
              "      <td>0.912775</td>\n",
              "      <td>0.935025</td>\n",
              "      <td>0.922817</td>\n",
              "      <td>0.927775</td>\n",
              "      <td>0.928100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.918492</td>\n",
              "      <td>0.914950</td>\n",
              "      <td>0.935292</td>\n",
              "      <td>0.923875</td>\n",
              "      <td>0.933167</td>\n",
              "      <td>0.932908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.921142</td>\n",
              "      <td>0.916937</td>\n",
              "      <td>0.935971</td>\n",
              "      <td>0.924575</td>\n",
              "      <td>0.937433</td>\n",
              "      <td>0.934471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.922150</td>\n",
              "      <td>0.918083</td>\n",
              "      <td>0.936433</td>\n",
              "      <td>0.925567</td>\n",
              "      <td>0.942750</td>\n",
              "      <td>0.936017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       128-64-32a    128-32a  128-64-32sgd  128-32sgd  128-64-32rms  128-32rms\n",
              "count   10.000000  10.000000     10.000000  10.000000     10.000000  10.000000\n",
              "mean     0.918658   0.914623      0.935365   0.923778      0.932525   0.931282\n",
              "std      0.002815   0.002809      0.000733   0.001201      0.006973   0.004279\n",
              "min      0.913100   0.909633      0.934250   0.921983      0.921100   0.922900\n",
              "25%      0.917413   0.912775      0.935025   0.922817      0.927775   0.928100\n",
              "50%      0.918492   0.914950      0.935292   0.923875      0.933167   0.932908\n",
              "75%      0.921142   0.916937      0.935971   0.924575      0.937433   0.934471\n",
              "max      0.922150   0.918083      0.936433   0.925567      0.942750   0.936017"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "j12vwQ5oEp8Y",
        "outputId": "6a2f07ff-7cb7-46a0-c706-25e6858b984b"
      },
      "source": [
        "test_3b_df.astype(np.float64).describe()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>128-64-32a</th>\n",
              "      <th>128-32a</th>\n",
              "      <th>128-64-32sgd</th>\n",
              "      <th>128-32sgd</th>\n",
              "      <th>128-64-32rms</th>\n",
              "      <th>128-32rms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.878100</td>\n",
              "      <td>0.878960</td>\n",
              "      <td>0.887110</td>\n",
              "      <td>0.884730</td>\n",
              "      <td>0.876610</td>\n",
              "      <td>0.881070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.002885</td>\n",
              "      <td>0.002484</td>\n",
              "      <td>0.001955</td>\n",
              "      <td>0.002074</td>\n",
              "      <td>0.006091</td>\n",
              "      <td>0.003348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.874200</td>\n",
              "      <td>0.874800</td>\n",
              "      <td>0.884500</td>\n",
              "      <td>0.881400</td>\n",
              "      <td>0.867900</td>\n",
              "      <td>0.876500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.875475</td>\n",
              "      <td>0.877975</td>\n",
              "      <td>0.885875</td>\n",
              "      <td>0.883150</td>\n",
              "      <td>0.871200</td>\n",
              "      <td>0.878450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.878550</td>\n",
              "      <td>0.879400</td>\n",
              "      <td>0.886800</td>\n",
              "      <td>0.885050</td>\n",
              "      <td>0.876900</td>\n",
              "      <td>0.881550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.879875</td>\n",
              "      <td>0.879850</td>\n",
              "      <td>0.887975</td>\n",
              "      <td>0.886450</td>\n",
              "      <td>0.881725</td>\n",
              "      <td>0.883500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.883000</td>\n",
              "      <td>0.883400</td>\n",
              "      <td>0.890300</td>\n",
              "      <td>0.887400</td>\n",
              "      <td>0.884400</td>\n",
              "      <td>0.885900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       128-64-32a    128-32a  128-64-32sgd  128-32sgd  128-64-32rms  128-32rms\n",
              "count   10.000000  10.000000     10.000000  10.000000     10.000000  10.000000\n",
              "mean     0.878100   0.878960      0.887110   0.884730      0.876610   0.881070\n",
              "std      0.002885   0.002484      0.001955   0.002074      0.006091   0.003348\n",
              "min      0.874200   0.874800      0.884500   0.881400      0.867900   0.876500\n",
              "25%      0.875475   0.877975      0.885875   0.883150      0.871200   0.878450\n",
              "50%      0.878550   0.879400      0.886800   0.885050      0.876900   0.881550\n",
              "75%      0.879875   0.879850      0.887975   0.886450      0.881725   0.883500\n",
              "max      0.883000   0.883400      0.890300   0.887400      0.884400   0.885900"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pp_CMgwFE4P"
      },
      "source": [
        "Классификатор Адам показал худшие результаты на трейне, но средние на тесте. Лушим из трёх испытанных можно считать SGD, который показал лучшие результаты и стабильность результатов на тесте.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GOY55kjFE7p"
      },
      "source": [
        "**Однодзначный вывод:** большое число нейронов в одном слое - не хорошо, лучше разбить на несколько сетей, т.к. возрастает число возможных комбинаций. число нейронов в слое меньщее или близкое числу классов - очень плохо (за кадром были проверены сети из 5, 6 и 10 слоёв с количеством нейронов 16, результат хуже, чем у 64-16). \n",
        "**Неоднозначный вывод:** лучшая сеть оказалась с небольшим числом слоёв и нейронов в каждом слое. Почему - не могу понять.\n",
        "\n",
        "Лучше проверять датасет на разных конфигурациях сети и делать тест на устойчивость результатов аккуратности."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56caHvRgLOM_"
      },
      "source": [
        "Собираем матрицы ошибок на лучшей сети - 128-64-32sgd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtZSHHofFFbS",
        "outputId": "aeb72fb2-d4a9-4f8e-916b-d762eeffe2bc"
      },
      "source": [
        "best_model_name = \"128-64-32sgd\"\n",
        "print(\"Работает модель \", best_model_name)\n",
        "best_model = keras.Sequential(\n",
        "[\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,),\n",
        "                kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                              stddev=0.15, \n",
        "                                  seed=int(datetime.now().timestamp()))),\n",
        "    layers.Dense(64, activation='relu', \n",
        "                kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                              stddev=0.15, \n",
        "                                  seed=int(datetime.now().timestamp()))),\n",
        "    layers.Dense(32, activation='relu',\n",
        "                kernel_initializer=initializers.RandomNormal(mean=0.0, \n",
        "                                                              stddev=0.15, \n",
        "                                  seed=int(datetime.now().timestamp()))),\n",
        "    layers.Dense(num_classes, activation=\"softmax\")\n",
        "]\n",
        ")\n",
        "# Можем посчитать метрики по всем классам.\n",
        "metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "\n",
        "best_model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=metrics)\n",
        "best_model.fit(train_images, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Работает модель  128-64-32sgd\n",
            "Epoch 1/15\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4401 - accuracy: 0.0000e+00 - precision_1: 0.7354 - recall_1: 0.2919 - val_loss: 0.7191 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8371 - val_recall_1: 0.6251\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6979 - accuracy: 0.0000e+00 - precision_1: 0.8377 - recall_1: 0.6475 - val_loss: 0.6185 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8477 - val_recall_1: 0.6926\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6131 - accuracy: 0.0000e+00 - precision_1: 0.8516 - recall_1: 0.7021 - val_loss: 0.5707 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8577 - val_recall_1: 0.7202\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.0000e+00 - precision_1: 0.8573 - recall_1: 0.7313 - val_loss: 0.5430 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8565 - val_recall_1: 0.7445\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5302 - accuracy: 0.0000e+00 - precision_1: 0.8673 - recall_1: 0.7513 - val_loss: 0.5217 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8666 - val_recall_1: 0.7563\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5127 - accuracy: 0.0000e+00 - precision_1: 0.8675 - recall_1: 0.7612 - val_loss: 0.5065 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8665 - val_recall_1: 0.7678\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4877 - accuracy: 0.0000e+00 - precision_1: 0.8732 - recall_1: 0.7774 - val_loss: 0.4886 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8751 - val_recall_1: 0.7757\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4802 - accuracy: 0.0000e+00 - precision_1: 0.8762 - recall_1: 0.7853 - val_loss: 0.4867 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8690 - val_recall_1: 0.7864\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4675 - accuracy: 0.0000e+00 - precision_1: 0.8754 - recall_1: 0.7923 - val_loss: 0.4917 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8646 - val_recall_1: 0.7792\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4531 - accuracy: 0.0000e+00 - precision_1: 0.8806 - recall_1: 0.7970 - val_loss: 0.4591 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8778 - val_recall_1: 0.7970\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4433 - accuracy: 0.0000e+00 - precision_1: 0.8848 - recall_1: 0.8063 - val_loss: 0.4693 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8669 - val_recall_1: 0.7864\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4383 - accuracy: 0.0000e+00 - precision_1: 0.8829 - recall_1: 0.8080 - val_loss: 0.4505 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8784 - val_recall_1: 0.8005\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4307 - accuracy: 0.0000e+00 - precision_1: 0.8851 - recall_1: 0.8114 - val_loss: 0.4420 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8828 - val_recall_1: 0.8091\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4218 - accuracy: 0.0000e+00 - precision_1: 0.8851 - recall_1: 0.8156 - val_loss: 0.4400 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8823 - val_recall_1: 0.8126\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4166 - accuracy: 0.0000e+00 - precision_1: 0.8896 - recall_1: 0.8193 - val_loss: 0.4331 - val_accuracy: 0.0000e+00 - val_precision_1: 0.8818 - val_recall_1: 0.8093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8e17954850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5k4S82Guq8"
      },
      "source": [
        "predictions = best_model.predict(\n",
        "    test_images\n",
        ")"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obg1ahuiMDeZ",
        "outputId": "e3db6f98-07e9-43ab-98dd-bc029e5e7a24"
      },
      "source": [
        "# Матрица ошибок методами TensorFlow\n",
        "tf.math.confusion_matrix(\n",
        "    y_test.argmax(axis=1), predictions.argmax(axis=1), num_classes=10, dtype=tf.dtypes.int32)\n"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
              "array([[820,   3,  15,  47,   4,   3,  93,   0,  15,   0],\n",
              "       [  3, 956,   6,  29,   3,   0,   2,   0,   1,   0],\n",
              "       [ 22,   2, 776,  13,  93,   1,  84,   0,   9,   0],\n",
              "       [ 39,  15,  13, 877,  22,   0,  26,   0,   8,   0],\n",
              "       [  1,   0, 154,  47, 682,   1, 106,   0,   9,   0],\n",
              "       [  0,   0,   0,   1,   0, 934,   0,  39,   2,  24],\n",
              "       [165,   2, 138,  49,  71,   0, 546,   0,  29,   0],\n",
              "       [  0,   0,   0,   0,   0,  53,   0, 886,   1,  60],\n",
              "       [  1,   1,   8,   5,   3,  10,  14,   5, 953,   0],\n",
              "       [  0,   0,   0,   0,   0,  17,   0,  39,   1, 943]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AdoQZ0JrMDtN",
        "outputId": "21c4410f-1583-411f-a9c0-6fbe3b04252a"
      },
      "source": [
        "# Преобразование в датафрейм\n",
        "cfmatrix = pd.DataFrame(np.array(tf.math.confusion_matrix(\n",
        "    y_test.argmax(axis=1), predictions.argmax(axis=1), num_classes=10, dtype=tf.dtypes.int32)),\n",
        "    columns=fashion_dict.values(),index=fashion_dict.values()\n",
        ")\n",
        "cfmatrix"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T-shirt/top</th>\n",
              "      <th>Trouser</th>\n",
              "      <th>Pullover</th>\n",
              "      <th>Dress</th>\n",
              "      <th>Coat</th>\n",
              "      <th>Sandal</th>\n",
              "      <th>Shirt</th>\n",
              "      <th>Sneaker</th>\n",
              "      <th>Bag</th>\n",
              "      <th>Ankle boot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T-shirt/top</th>\n",
              "      <td>820</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>47</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Trouser</th>\n",
              "      <td>3</td>\n",
              "      <td>956</td>\n",
              "      <td>6</td>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pullover</th>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>776</td>\n",
              "      <td>13</td>\n",
              "      <td>93</td>\n",
              "      <td>1</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dress</th>\n",
              "      <td>39</td>\n",
              "      <td>15</td>\n",
              "      <td>13</td>\n",
              "      <td>877</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coat</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>154</td>\n",
              "      <td>47</td>\n",
              "      <td>682</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sandal</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>934</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shirt</th>\n",
              "      <td>165</td>\n",
              "      <td>2</td>\n",
              "      <td>138</td>\n",
              "      <td>49</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>546</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sneaker</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>886</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bag</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>953</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ankle boot</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>943</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             T-shirt/top  Trouser  Pullover  ...  Sneaker  Bag  Ankle boot\n",
              "T-shirt/top          820        3        15  ...        0   15           0\n",
              "Trouser                3      956         6  ...        0    1           0\n",
              "Pullover              22        2       776  ...        0    9           0\n",
              "Dress                 39       15        13  ...        0    8           0\n",
              "Coat                   1        0       154  ...        0    9           0\n",
              "Sandal                 0        0         0  ...       39    2          24\n",
              "Shirt                165        2       138  ...        0   29           0\n",
              "Sneaker                0        0         0  ...      886    1          60\n",
              "Bag                    1        1         8  ...        5  953           0\n",
              "Ankle boot             0        0         0  ...       39    1         943\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "id": "zo7vDM9ARTCS",
        "outputId": "53497a5e-bcb3-4f53-cd3b-1afc8f072693"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = cfmatrix.copy()\n",
        "df = np.array(df.values, dtype=np.int32)\n",
        "fig, ax = plt.subplots(figsize=(12,12)) \n",
        "ax = sns.heatmap(df, annot=True, ax=ax)\n",
        "\n",
        "ax.set_xticklabels(cfmatrix.columns, rotation=90)\n",
        "ax.set_yticklabels(cfmatrix.index)\n",
        "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90 )\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Плохие результаты только у класса shirt, они очень похоже на T-Shitr/top и на Pulover.\n",
        "# Это может быть паолне ожидаемо, т.к. \"контуры\" этого класса одежды похожи\n",
        "# Ещё один не лучший результат у Coat по той же причине."
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXGNE82CU8ZG",
        "outputId": "3f2a27c1-08be-4462-f127-8c82ace5c36a"
      },
      "source": [
        "from sklearn.metrics import recall_score, precision_score\n",
        "\n",
        "\n",
        "recall_score(y_test.argmax(axis=1), predictions.argmax(axis=1), average=None)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.82 , 0.956, 0.776, 0.877, 0.682, 0.934, 0.546, 0.886, 0.953,\n",
              "       0.943])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_vhehW7S9UW",
        "outputId": "a0308cba-a66a-4a38-f02d-eccfd428b200"
      },
      "source": [
        "precision_score(y_test.argmax(axis=1), predictions.argmax(axis=1), average=None)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.78020932, 0.97650664, 0.6990991 , 0.82116105, 0.77676538,\n",
              "       0.91658489, 0.62686567, 0.91434469, 0.9270428 , 0.91820837])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XC757twVt79"
      },
      "source": [
        "cfmatrix.loc[10] = precision_score(y_test.argmax(axis=1), predictions.argmax(axis=1), average=None)"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9fQjwv6WPAF"
      },
      "source": [
        "cfmatrix.loc[11] = recall_score(y_test.argmax(axis=1), predictions.argmax(axis=1), average=None)"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "5XCnKKrNWUD-",
        "outputId": "73da56d5-23c1-4eed-cec4-b4ad1690fba8"
      },
      "source": [
        "cfmatrix.rename(index={10: 'precision_score', 11 : 'recall_score'})"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T-shirt/top</th>\n",
              "      <th>Trouser</th>\n",
              "      <th>Pullover</th>\n",
              "      <th>Dress</th>\n",
              "      <th>Coat</th>\n",
              "      <th>Sandal</th>\n",
              "      <th>Shirt</th>\n",
              "      <th>Sneaker</th>\n",
              "      <th>Bag</th>\n",
              "      <th>Ankle boot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T-shirt/top</th>\n",
              "      <td>820.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Trouser</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>956.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pullover</th>\n",
              "      <td>22.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>776.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dress</th>\n",
              "      <td>39.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>877.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coat</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>154.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>682.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sandal</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>934.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shirt</th>\n",
              "      <td>165.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>546.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sneaker</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>886.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bag</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>953.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ankle boot</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>943.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision_score</th>\n",
              "      <td>0.780209</td>\n",
              "      <td>0.976507</td>\n",
              "      <td>0.699099</td>\n",
              "      <td>0.821161</td>\n",
              "      <td>0.776765</td>\n",
              "      <td>0.916585</td>\n",
              "      <td>0.626866</td>\n",
              "      <td>0.914345</td>\n",
              "      <td>0.927043</td>\n",
              "      <td>0.918208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_score</th>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>0.776000</td>\n",
              "      <td>0.877000</td>\n",
              "      <td>0.682000</td>\n",
              "      <td>0.934000</td>\n",
              "      <td>0.546000</td>\n",
              "      <td>0.886000</td>\n",
              "      <td>0.953000</td>\n",
              "      <td>0.943000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 T-shirt/top     Trouser  ...         Bag  Ankle boot\n",
              "T-shirt/top       820.000000    3.000000  ...   15.000000    0.000000\n",
              "Trouser             3.000000  956.000000  ...    1.000000    0.000000\n",
              "Pullover           22.000000    2.000000  ...    9.000000    0.000000\n",
              "Dress              39.000000   15.000000  ...    8.000000    0.000000\n",
              "Coat                1.000000    0.000000  ...    9.000000    0.000000\n",
              "Sandal              0.000000    0.000000  ...    2.000000   24.000000\n",
              "Shirt             165.000000    2.000000  ...   29.000000    0.000000\n",
              "Sneaker             0.000000    0.000000  ...    1.000000   60.000000\n",
              "Bag                 1.000000    1.000000  ...  953.000000    0.000000\n",
              "Ankle boot          0.000000    0.000000  ...    1.000000  943.000000\n",
              "precision_score     0.780209    0.976507  ...    0.927043    0.918208\n",
              "recall_score        0.820000    0.956000  ...    0.953000    0.943000\n",
              "\n",
              "[12 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyHM4T3IS8eK"
      },
      "source": [
        "Вывели полноту и точность для каждого класса, добавили в таблицу.\n",
        "\n",
        "Не удивительно, что для \"рубашкоподобной\" верхней одежды имеем не высокие результаты, т.к. силуэты этих вещей похожи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXxSoBUb-RJJ"
      },
      "source": [
        "Метрики\n",
        "https://keras.io/examples/vision/metric_learning/\n"
      ]
    }
  ]
}